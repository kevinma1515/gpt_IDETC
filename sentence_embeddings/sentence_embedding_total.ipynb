{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88316a13",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e25a774",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Design prompt 1, human prompts\n",
    "human1 = []\n",
    "with open(\"data/amazonTurkDesPrompt1.csv\", 'r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    for row in csvreader:\n",
    "        human1.append(row[0])\n",
    "human1 = [i.replace('\\n',' ') for i in human1]    # Removing the line breaks as they mess with tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5b877c3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "human2 = []\n",
    "with open(\"data/amazonTurkDesPrompt2.csv\", 'r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    for row in csvreader:\n",
    "        human2.append(row[0])\n",
    "human2 = [i.replace('\\n',' ') for i in human2]    # Removing the line breaks as they mess with tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e4f9c5c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "human3 = []\n",
    "with open(\"data/amazonTurkDesPrompt3.csv\", 'r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    for row in csvreader:\n",
    "        human3.append(row[0])\n",
    "human3 = [i.replace('\\n',' ') for i in human3]    # Removing the line breaks as they mess with tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65844746",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "human4 = []\n",
    "with open(\"data/amazonTurkDesPrompt4.csv\", 'r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    for row in csvreader:\n",
    "        human4.append(row[0])\n",
    "human4 = [i.replace('\\n',' ') for i in human4] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd07bed5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "human5 = []\n",
    "with open(\"data/amazonTurkDesPrompt5.csv\", 'r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    for row in csvreader:\n",
    "        human5.append(row[0])\n",
    "human5 = [i.replace('\\n',' ') for i in human5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e39f5b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "human6 = []\n",
    "with open(\"data/amazonTurkDesPrompt6.csv\", 'r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    for row in csvreader:\n",
    "        human6.append(row[0])\n",
    "human6 = [i.replace('\\n',' ') for i in human6] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d131868a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "human7 = []\n",
    "with open(\"data/amazonTurkDesPrompt7.csv\", 'r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    for row in csvreader:\n",
    "        human7.append(row[0])\n",
    "human7 = [i.replace('\\n',' ') for i in human7] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a4a59e6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "human8 = []\n",
    "with open(\"data/amazonTurkDesPrompt8.csv\", 'r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    for row in csvreader:\n",
    "        human8.append(row[0])\n",
    "human8 = [i.replace('\\n',' ') for i in human8] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "233d1612",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "human9 = []\n",
    "with open(\"data/amazonTurkDesPrompt9.csv\", 'r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    for row in csvreader:\n",
    "        human9.append(row[0])\n",
    "human9 = [i.replace('\\n',' ') for i in human9] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccc13e0d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "human10 = []\n",
    "with open(\"data/amazonTurkDesPrompt10.csv\", 'r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    for row in csvreader:\n",
    "        human10.append(row[0])\n",
    "human10 = [i.replace('\\n',' ') for i in human10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adaba7e6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "human11 = []\n",
    "with open(\"data/amazonTurkDesPrompt11.csv\", 'r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    for row in csvreader:\n",
    "        human11.append(row[0])\n",
    "human11 = [i.replace('\\n',' ') for i in human11] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab4dfcda",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "humanNA = []\n",
    "with open(\"data/amazonTurkDesPromptNA.csv\", 'r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    for row in csvreader:\n",
    "        humanNA.append(row[0])\n",
    "humanNA = [i.replace('\\n',' ') for i in humanNA] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77698907",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Design prompt 1, gpt prompts\n",
    "desprompt1 = pd.read_csv('data/Design_Prompt1.csv', sep = \",\", header=None)\n",
    "lst1 = []\n",
    "for d in desprompt1.values:\n",
    "    lst1.append(d[0])\n",
    "gpt1 = []\n",
    "for i in range(len(lst1)):\n",
    "    mod_statements1 = lst1[i].replace(lst1[i][:3], '')\n",
    "    gpt1.append(mod_statements1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b73ee13d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Design Prompt 2, gpt prompts\n",
    "desprompt2 = pd.read_csv('data/Design_Prompt2.csv', sep = \",\", header = None)\n",
    "lst2 = []\n",
    "for d in desprompt2.values:\n",
    "    lst2.append(d[0])\n",
    "gpt2 = []\n",
    "for i in range(len(lst2)):\n",
    "    mod_statements2 = lst2[i].replace(lst2[i][:3], '')\n",
    "    gpt2.append(mod_statements2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d903a168",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Design Prompt 3, gpt prompts\n",
    "desprompt3 = pd.read_csv('data/Design_Prompt3.csv', sep = \",\", header = None)\n",
    "lst3 = []\n",
    "for d in desprompt3.values:\n",
    "    lst3.append(d[0])\n",
    "gpt3 = []\n",
    "for i in range(len(lst3)):\n",
    "    mod_statements3 = lst3[i].replace(lst3[i][:3], '')\n",
    "    gpt3.append(mod_statements3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ebfe381",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "desprompt4 = pd.read_csv('data/Design_Prompt4.csv', sep = \",\", header = None)\n",
    "lst4 = []\n",
    "for d in desprompt4.values:\n",
    "    lst4.append(d[0])\n",
    "gpt4 = []\n",
    "for i in range(len(lst4)):\n",
    "    mod_statements4 = lst4[i].replace(lst4[i][:3], '')\n",
    "    gpt4.append(mod_statements4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29ff4f02",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "desprompt5 = pd.read_csv('data/Design_Prompt5.csv', sep = \",\", header = None)\n",
    "lst5 = []\n",
    "for d in desprompt5.values:\n",
    "    lst5.append(d[0])\n",
    "gpt5 = []\n",
    "for i in range(len(lst5)):\n",
    "    mod_statements5 = lst5[i].replace(lst5[i][:3], '')\n",
    "    gpt5.append(mod_statements5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53a14dea",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "desprompt6 = pd.read_csv('data/Design_Prompt6.csv', sep = \",\", header = None)\n",
    "lst6 = []\n",
    "for d in desprompt6.values:\n",
    "    lst6.append(d[0])\n",
    "gpt6 = []\n",
    "for i in range(len(lst6)):\n",
    "    mod_statements6 = lst6[i].replace(lst6[i][:3], '')\n",
    "    gpt6.append(mod_statements6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b96b3e6f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "desprompt7 = pd.read_csv('data/Design_Prompt7.csv', sep = \",\", header = None)\n",
    "lst7 = []\n",
    "for d in desprompt7.values:\n",
    "    lst7.append(d[0])\n",
    "gpt7 = []\n",
    "for i in range(len(lst7)):\n",
    "    mod_statements7 = lst7[i].replace(lst7[i][:3], '')\n",
    "    gpt7.append(mod_statements7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1412a0db",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "desprompt8 = pd.read_csv('data/Design_Prompt8.csv', sep = \",\", header = None)\n",
    "lst8 = []\n",
    "for d in desprompt8.values:\n",
    "    lst8.append(d[0])\n",
    "gpt8 = []\n",
    "for i in range(len(lst8)):\n",
    "    mod_statements8 = lst8[i].replace(lst8[i][:3], '')\n",
    "    gpt8.append(mod_statements8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b59d06c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "desprompt9 = pd.read_csv('data/Design_Prompt9.csv', sep = \",\", header = None)\n",
    "lst9 = []\n",
    "for d in desprompt9.values:\n",
    "    lst9.append(d[0])\n",
    "gpt9 = []\n",
    "for i in range(len(lst9)):\n",
    "    mod_statements9 = lst9[i].replace(lst9[i][:3], '')\n",
    "    gpt9.append(mod_statements9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27d3f3d0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "desprompt10 = pd.read_csv('data/Design_Prompt10.csv', sep = \",\", header = None)\n",
    "lst10 = []\n",
    "for d in desprompt10.values:\n",
    "    lst10.append(d[0])\n",
    "gpt10 = []\n",
    "for i in range(len(lst10)):\n",
    "    mod_statements10 = lst10[i].replace(lst10[i][:3], '')\n",
    "    gpt10.append(mod_statements10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be24fa42",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "desprompt11 = pd.read_csv('data/Design_Prompt11.csv', sep = \",\", header = None)\n",
    "lst11 = []\n",
    "for d in desprompt11.values:\n",
    "    lst11.append(d[0])\n",
    "gpt11 = []\n",
    "for i in range(len(lst11)):\n",
    "    mod_statements11 = lst11[i].replace(lst11[i][:3], '')\n",
    "    gpt11.append(mod_statements11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7fa0d1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "desprompt12 = pd.read_csv('data/Design_Prompt12.csv', sep = \",\", header = None)\n",
    "lst12 = []\n",
    "for d in desprompt12.values:\n",
    "    lst12.append(d[0])\n",
    "gpt12 = []\n",
    "for i in range(len(lst12)):\n",
    "    mod_statements12 = lst12[i].replace(lst12[i][:3], '')\n",
    "    gpt12.append(mod_statements12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "231a2699",
   "metadata": {},
   "outputs": [],
   "source": [
    "despromptNA = pd.read_csv('data/Design_PromptNA.csv', sep = \",\", header = None)\n",
    "lstNA = []\n",
    "for d in despromptNA.values:\n",
    "    lstNA.append(d[0])\n",
    "gptNA = []\n",
    "for i in range(len(lstNA)):\n",
    "    mod_statementsNA = lstNA[i].replace(lstNA[i][:3], '')\n",
    "    gptNA.append(mod_statementsNA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e19c2fcf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# embed data\n",
    "# this is brute forced. Just easier to debug sometimes...\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "gpt1_embeddings = model.encode(gpt1)\n",
    "human1_embeddings = model.encode(human1)\n",
    "\n",
    "gpt2_embeddings = model.encode(gpt2)\n",
    "human2_embeddings = model.encode(human2)\n",
    "\n",
    "gpt3_embeddings = model.encode(gpt3)\n",
    "human3_embeddings = model.encode(human3)\n",
    "\n",
    "gpt4_embeddings = model.encode(gpt4)\n",
    "human4_embeddings = model.encode(human4)\n",
    "\n",
    "gpt5_embeddings = model.encode(gpt5)\n",
    "human5_embeddings = model.encode(human5)\n",
    "\n",
    "gpt7_embeddings = model.encode(gpt7)\n",
    "human7_embeddings = model.encode(human7)\n",
    "\n",
    "gpt8_embeddings = model.encode(gpt8)\n",
    "human8_embeddings = model.encode(human8)\n",
    "\n",
    "gpt9_embeddings = model.encode(gpt9)\n",
    "human9_embeddings = model.encode(human9)\n",
    "\n",
    "gpt10_embeddings = model.encode(gpt10)\n",
    "human10_embeddings = model.encode(human10)\n",
    "\n",
    "gpt11_embeddings = model.encode(gpt11)\n",
    "human11_embeddings = model.encode(human11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d141e2ac",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bert_human1 = torch.from_numpy(human1_embeddings)\n",
    "bert_gpt1 = torch.from_numpy(gpt1_embeddings)\n",
    "\n",
    "bert_human2 = torch.from_numpy(human2_embeddings)\n",
    "bert_gpt2 = torch.from_numpy(gpt2_embeddings)\n",
    "\n",
    "bert_human3 = torch.from_numpy(human3_embeddings)\n",
    "bert_gpt3 = torch.from_numpy(gpt3_embeddings)\n",
    "\n",
    "bert_human4 = torch.from_numpy(human4_embeddings)\n",
    "bert_gpt4 = torch.from_numpy(gpt4_embeddings)\n",
    "\n",
    "bert_human5 = torch.from_numpy(human5_embeddings)\n",
    "bert_gpt5 = torch.from_numpy(gpt5_embeddings)\n",
    "\n",
    "bert_human7 = torch.from_numpy(human7_embeddings)\n",
    "bert_gpt7 = torch.from_numpy(gpt7_embeddings)\n",
    "\n",
    "bert_human8 = torch.from_numpy(human8_embeddings)\n",
    "bert_gpt8 = torch.from_numpy(gpt8_embeddings)\n",
    "\n",
    "bert_human9 = torch.from_numpy(human9_embeddings)\n",
    "bert_gpt9 = torch.from_numpy(gpt9_embeddings)\n",
    "\n",
    "bert_human10 = torch.from_numpy(human10_embeddings)\n",
    "bert_gpt10 = torch.from_numpy(gpt10_embeddings)\n",
    "\n",
    "bert_human11 = torch.from_numpy(human11_embeddings)\n",
    "bert_gpt11 = torch.from_numpy(gpt11_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "706931f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt6_embeddings = model.encode(gpt6)\n",
    "human6_embeddings = model.encode(human6)\n",
    "\n",
    "bert_human6 = torch.from_numpy(human6_embeddings)\n",
    "bert_gpt6 = torch.from_numpy(gpt6_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c33c863b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gptNA_embeddings = model.encode(gptNA)\n",
    "humanNA_embeddings = model.encode(humanNA)\n",
    "\n",
    "bert_humanNA = torch.from_numpy(humanNA_embeddings)\n",
    "bert_gptNA = torch.from_numpy(gptNA_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f8c67eb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "# visualize embeddings\n",
    "writer = SummaryWriter('embeddings_total')\n",
    "metadata = [('human1', line) for line in human1] + [('gpt1', line) for line in gpt1] +\\\n",
    "            [('human2', line) for line in human2] + [('gpt2', line) for line in gpt2]+\\\n",
    "[('human3', line) for line in human3] + [('gpt3', line) for line in gpt3]+\\\n",
    "[('human4', line) for line in human4] + [('gpt4', line) for line in gpt4]+\\\n",
    "[('human5', line) for line in human5] + [('gpt5', line) for line in gpt5]+\\\n",
    "[('human7', line) for line in human7] + [('gpt7', line) for line in gpt7]+\\\n",
    "[('human6', line) for line in human6] + [('gpt6', line) for line in gpt6]+\\\n",
    "[('human8', line) for line in human8] + [('gpt8', line) for line in gpt8]+\\\n",
    "[('human9', line) for line in human9] + [('gpt9', line) for line in gpt9]+\\\n",
    "[('human10', line) for line in human10] + [('gpt10', line) for line in gpt10]+\\\n",
    "[('human11', line) for line in human11] + [('gpt11', line) for line in gpt11]+\\\n",
    "[('humanNA', line) for line in humanNA] + [('gptNA', line) for line in gptNA]\n",
    "\n",
    "\n",
    "writer.add_embedding(torch.cat((bert_human1, bert_gpt1, bert_human2, bert_gpt2, bert_human3, bert_gpt3, bert_human4, \n",
    "                                bert_gpt4, bert_human5, bert_gpt5, bert_human6, bert_gpt6, bert_human7, bert_gpt7, bert_human8, \n",
    "                                bert_gpt8, bert_human9, bert_gpt9, bert_human10, \n",
    "                                bert_gpt10, bert_human11, bert_gpt11, bert_humanNA, bert_gptNA), 0), metadata=metadata, metadata_header=['writer', 'prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c7eaa5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "# visualize embeddings\n",
    "writer = SummaryWriter('embeddings1')\n",
    "metadata = [('human1', line) for line in human1] + [('gpt1', line) for line in gpt1]\n",
    "writer.add_embedding(torch.cat((bert_human1, bert_gpt1)),metadata = metadata, metadata_header = ['writer', 'prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c56269a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "# visualize embeddings\n",
    "writer = SummaryWriter('embeddings2')\n",
    "metadata = [('human2', line) for line in human2] + [('gpt2', line) for line in gpt2]\n",
    "writer.add_embedding(torch.cat((bert_human2, bert_gpt2)),metadata = metadata, metadata_header = ['writer', 'prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9acc80de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "# visualize embeddings\n",
    "writer = SummaryWriter('embeddings3')\n",
    "metadata = [('human3', line) for line in human3] + [('gpt3', line) for line in gpt3]\n",
    "writer.add_embedding(torch.cat((bert_human3, bert_gpt3)),metadata = metadata, metadata_header = ['writer', 'prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1efbb214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "# visualize embeddings\n",
    "writer = SummaryWriter('embeddings4')\n",
    "metadata = [('human4', line) for line in human4] + [('gpt4', line) for line in gpt4]\n",
    "writer.add_embedding(torch.cat((bert_human4, bert_gpt4)),metadata = metadata, metadata_header = ['writer', 'prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5de21e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "# visualize embeddings\n",
    "writer = SummaryWriter('embeddings5')\n",
    "metadata = [('human5', line) for line in human5] + [('gpt5', line) for line in gpt5]\n",
    "writer.add_embedding(torch.cat((bert_human5, bert_gpt5)),metadata = metadata, metadata_header = ['writer', 'prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c557a345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "# visualize embeddings\n",
    "writer = SummaryWriter('embeddings6')\n",
    "metadata = [('human6', line) for line in human6] + [('gpt6', line) for line in gpt6]\n",
    "writer.add_embedding(torch.cat((bert_human6, bert_gpt6)),metadata = metadata, metadata_header = ['writer', 'prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f2ddc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "# visualize embeddings\n",
    "writer = SummaryWriter('embeddings7')\n",
    "metadata = [('human7', line) for line in human7] + [('gpt7', line) for line in gpt7]\n",
    "writer.add_embedding(torch.cat((bert_human7, bert_gpt7)),metadata = metadata, metadata_header = ['writer', 'prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "228500e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "# visualize embeddings\n",
    "writer = SummaryWriter('embeddings8')\n",
    "metadata = [('human8', line) for line in human8] + [('gpt8', line) for line in gpt8]\n",
    "writer.add_embedding(torch.cat((bert_human8, bert_gpt8)),metadata = metadata, metadata_header = ['writer', 'prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c64521a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "# visualize embeddings\n",
    "writer = SummaryWriter('embeddings9')\n",
    "metadata = [('human9', line) for line in human9] + [('gpt9', line) for line in gpt9]\n",
    "writer.add_embedding(torch.cat((bert_human9, bert_gpt9)),metadata = metadata, metadata_header = ['writer', 'prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6a054082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "# visualize embeddings\n",
    "writer = SummaryWriter('embeddings10')\n",
    "metadata = [('human10', line) for line in human10] + [('gpt10', line) for line in gpt10]\n",
    "writer.add_embedding(torch.cat((bert_human10, bert_gpt10)),metadata = metadata, metadata_header = ['writer', 'prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cc5ef8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "# visualize embeddings\n",
    "writer = SummaryWriter('embeddings11')\n",
    "metadata = [('human11', line) for line in human11] + [('gpt11', line) for line in gpt11]\n",
    "writer.add_embedding(torch.cat((bert_human11, bert_gpt11)),metadata = metadata, metadata_header = ['writer', 'prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "292078be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "# visualize embeddings\n",
    "writer = SummaryWriter('embeddingsNA')\n",
    "metadata = [('humanNA', line) for line in humanNA] + [('gptNA', line) for line in gptNA]\n",
    "writer.add_embedding(torch.cat((bert_humanNA, bert_gptNA)),metadata = metadata, metadata_header = ['writer', 'prompt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55272d6a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Run in terminal: tensorboard --logdir=\"embeddings\\\" --host localhost http://localhost:6006/ to open Tensorboard Refresh page.\n",
    "Note when you run from anaconda, conda activate chatgpt -> cd chatgpt -> run the terminal command above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fadd9b6",
   "metadata": {},
   "source": [
    "## How to interpret the cosine distance?\n",
    "\n",
    "Let two vectors $ a, b, \\theta$ be obtained by the scalar product and the norm of the vectors:\n",
    "$$ \\cos(\\theta) = \\frac{a \\cdot b}{||a|| \\cdot ||b||} $$\n",
    "Since $\\cos(\\theta)$ value is in the range $[-1 , 1]$:\n",
    "* $-1$ value will indicate strongly opposite vectors (a and b are very different)\n",
    "* $0$ independent (orthogonal) vectors (no correlation between a and b)\n",
    "* $1$ similar (positive co-linear) vecctors. Intermediate values are used to assess the degree of similarity. (a and b are very similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "41f0b8ae",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from statistics import mean\n",
    "from itertools import combinations\n",
    "generated_embeddings = [gpt1_embeddings, gpt2_embeddings, gpt3_embeddings, gpt4_embeddings, gpt5_embeddings, gpt6_embeddings, gpt7_embeddings, gpt8_embeddings, gpt9_embeddings, gpt10_embeddings, gpt11_embeddings, gptNA_embeddings]\n",
    "human_embeddings = [human1_embeddings, human2_embeddings, human3_embeddings, human4_embeddings, human5_embeddings, human6_embeddings, human7_embeddings, human8_embeddings, human9_embeddings, human10_embeddings, human11_embeddings, humanNA_embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b2e3cb3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Cosine Distance between human and generated embeddings: 0.32623544335365295\n",
      "Average Cosine Distance between human and generated embeddings: 0.3270595967769623\n",
      "Average Cosine Distance between human and generated embeddings: 0.3432041108608246\n",
      "Average Cosine Distance between human and generated embeddings: 0.47904449701309204\n",
      "Average Cosine Distance between human and generated embeddings: 0.3175671696662903\n",
      "Average Cosine Distance between human and generated embeddings: 0.5164839029312134\n",
      "Average Cosine Distance between human and generated embeddings: 0.25225353240966797\n",
      "Average Cosine Distance between human and generated embeddings: 0.40128087997436523\n",
      "Average Cosine Distance between human and generated embeddings: 0.4363851845264435\n",
      "Average Cosine Distance between human and generated embeddings: 0.31657132506370544\n",
      "Average Cosine Distance between human and generated embeddings: 0.27409476041793823\n",
      "Average Cosine Distance between human and generated embeddings: 0.27485352754592896\n"
     ]
    }
   ],
   "source": [
    "# enumerate through generated_embeddings to get (100x384) or (99x384) vectors\n",
    "distances_prompt = []\n",
    "iterate = list(range(100))\n",
    "for count in range(len(generated_embeddings)):\n",
    "    distances_row = []\n",
    "    for combo in combinations(iterate, 2):\n",
    "        # dot product \n",
    "        distance = np.dot(human_embeddings[count][combo[0],:], generated_embeddings[count][combo[1],:])/(norm(human_embeddings[count][combo[0],:])*norm(generated_embeddings[count][combo[1],:]))\n",
    "        distances_row.append(distance)\n",
    "    distances_prompt.append(distances_row)\n",
    "    print(f\"Average Cosine Distance between human and generated embeddings: {np.mean(distances_row)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6e79f122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Cosine Distance between human and generated embeddings: 0.7372208833694458\n",
      "Average Cosine Distance between human and generated embeddings: 0.6272337436676025\n",
      "Average Cosine Distance between human and generated embeddings: 0.7272030115127563\n",
      "Average Cosine Distance between human and generated embeddings: 0.7775649428367615\n",
      "Average Cosine Distance between human and generated embeddings: 0.7960060834884644\n",
      "Average Cosine Distance between human and generated embeddings: 0.8071823716163635\n",
      "Average Cosine Distance between human and generated embeddings: 0.7677319645881653\n",
      "Average Cosine Distance between human and generated embeddings: 0.704262375831604\n",
      "Average Cosine Distance between human and generated embeddings: 0.7703189253807068\n",
      "Average Cosine Distance between human and generated embeddings: 0.7649713158607483\n",
      "Average Cosine Distance between human and generated embeddings: 0.7382302284240723\n",
      "Average Cosine Distance between human and generated embeddings: 0.7526814937591553\n"
     ]
    }
   ],
   "source": [
    "# enumerate through generated_embeddings to get (100x384)\n",
    "distances_prompt = []\n",
    "iterate = list(range(100))\n",
    "# index from 0-12\n",
    "for count in range(len(generated_embeddings)):\n",
    "    distances_row = []\n",
    "    max_distance = -1e9\n",
    "    # combinatorial match of [1,100] for pairwise\n",
    "    for combo in combinations(iterate, 2):\n",
    "        # dot product \n",
    "        distance = np.dot(human_embeddings[count][combo[0],:], generated_embeddings[count][combo[1],:])/(norm(human_embeddings[count][combo[0],:])*norm(generated_embeddings[count][combo[1],:]))\n",
    "        if distance > max_distance:\n",
    "            max_distance = distance\n",
    "        distances_row.append(max_distance)\n",
    "    distances_prompt.append(distances_row)\n",
    "    print(f\"Average Cosine Distance between human and generated embeddings: {np.mean(distances_row)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6c1cf315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4950"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(distances_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3ed1b9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 384)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7ce25c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_embeddings shape (100, 384)\n",
      "human_embeddings shape (100, 384)\n",
      "generated_embeddings shape (100, 384)\n",
      "human_embeddings shape (100, 384)\n",
      "generated_embeddings shape (100, 384)\n",
      "human_embeddings shape (100, 384)\n",
      "generated_embeddings shape (100, 384)\n",
      "human_embeddings shape (100, 384)\n",
      "generated_embeddings shape (100, 384)\n",
      "human_embeddings shape (100, 384)\n",
      "generated_embeddings shape (100, 384)\n",
      "human_embeddings shape (100, 384)\n",
      "generated_embeddings shape (100, 384)\n",
      "human_embeddings shape (100, 384)\n",
      "generated_embeddings shape (100, 384)\n",
      "human_embeddings shape (100, 384)\n",
      "generated_embeddings shape (100, 384)\n",
      "human_embeddings shape (100, 384)\n",
      "generated_embeddings shape (100, 384)\n",
      "human_embeddings shape (100, 384)\n",
      "generated_embeddings shape (100, 384)\n",
      "human_embeddings shape (100, 384)\n",
      "generated_embeddings shape (100, 384)\n",
      "human_embeddings shape (100, 384)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(generated_embeddings)):\n",
    "    print('generated_embeddings shape', generated_embeddings[i].shape)\n",
    "    print('human_embeddings shape', human_embeddings[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fc279fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average:  0.35607556\n",
      "standard deviation:  0.07988324\n"
     ]
    }
   ],
   "source": [
    "print('average: ', np.mean(distances))\n",
    "print('standard deviation: ', np.std(distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eca8d0d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.07354169,  0.05152091, -0.04160079, ..., -0.08609055,\n",
       "         -0.06903829,  0.07689107],\n",
       "        [-0.03084917,  0.12248117, -0.05312356, ..., -0.02598694,\n",
       "          0.00896085,  0.01969136],\n",
       "        [-0.0083613 , -0.02996279,  0.03444409, ..., -0.04331712,\n",
       "         -0.02330872,  0.03555185],\n",
       "        ...,\n",
       "        [ 0.05295016,  0.01373888, -0.02087503, ..., -0.00483859,\n",
       "          0.01642857, -0.057293  ],\n",
       "        [ 0.03174666,  0.00547677, -0.07130402, ...,  0.01611543,\n",
       "         -0.00663609,  0.03332655],\n",
       "        [-0.07669905,  0.08392771, -0.01675376, ..., -0.05440386,\n",
       "         -0.04658066,  0.07163215]], dtype=float32),\n",
       " array([[-0.07307021,  0.06389402, -0.04105479, ..., -0.07164105,\n",
       "          0.00118816,  0.05867276],\n",
       "        [-0.0175827 ,  0.11671401,  0.04160567, ..., -0.05293673,\n",
       "         -0.03432265,  0.06130178],\n",
       "        [-0.14772844,  0.05603454, -0.03409488, ..., -0.0357421 ,\n",
       "         -0.0155123 , -0.02847553],\n",
       "        ...,\n",
       "        [-0.1089557 ,  0.11090319,  0.01564019, ..., -0.04427239,\n",
       "          0.01106437,  0.02552062],\n",
       "        [-0.07229508,  0.04538236, -0.06084692, ..., -0.05895914,\n",
       "          0.0362076 ,  0.01212287],\n",
       "        [-0.07387491,  0.10402425, -0.00990104, ..., -0.09076039,\n",
       "         -0.07272806,  0.07288053]], dtype=float32),\n",
       " array([[-1.5916348e-02,  6.6009030e-02, -2.3783518e-04, ...,\n",
       "          1.0914160e-05,  3.9997605e-05, -9.1188829e-03],\n",
       "        [-1.9380907e-03,  5.6339577e-02,  2.2381963e-02, ...,\n",
       "          4.7700352e-04,  6.0194857e-02,  3.3470849e-03],\n",
       "        [ 1.5144838e-02,  3.5295274e-02,  4.2999042e-03, ...,\n",
       "          3.0199094e-02,  8.7943217e-03,  3.3212965e-03],\n",
       "        ...,\n",
       "        [ 7.0361691e-03,  4.4476844e-02, -1.3686864e-03, ...,\n",
       "          9.2876136e-02,  3.4146950e-02, -7.5347410e-03],\n",
       "        [ 6.6905511e-03,  3.8164128e-02, -1.1930837e-02, ...,\n",
       "          6.3235447e-02, -3.6968723e-02, -4.0142320e-02],\n",
       "        [-3.0230720e-02,  1.1508557e-01, -1.2095241e-02, ...,\n",
       "          3.1198122e-02, -5.5594053e-02, -3.7862565e-02]], dtype=float32),\n",
       " array([[-5.9273902e-02, -1.8829209e-03,  3.1711128e-02, ...,\n",
       "          3.2462951e-02, -2.7068753e-02, -3.9977275e-02],\n",
       "        [ 6.5188673e-03,  4.6116065e-02,  7.0556790e-02, ...,\n",
       "          8.9820579e-02, -8.1339799e-02,  4.4463757e-02],\n",
       "        [ 1.2105356e-03,  4.3282327e-03,  1.5004859e-02, ...,\n",
       "          5.2089542e-02, -1.4204554e-03, -4.0399093e-02],\n",
       "        ...,\n",
       "        [-5.5817548e-02, -1.0888167e-02,  2.4057740e-02, ...,\n",
       "          4.0353827e-02, -1.4483667e-02, -2.0518877e-02],\n",
       "        [-5.6799360e-02, -8.3119273e-03,  3.2000348e-02, ...,\n",
       "          4.3590821e-02,  2.6709247e-02, -5.3935073e-02],\n",
       "        [ 1.1955325e-03, -6.3613420e-06,  6.0106455e-03, ...,\n",
       "          6.3283086e-02,  4.7650281e-02, -8.1872828e-03]], dtype=float32),\n",
       " array([[-0.09659813,  0.0205404 ,  0.02748104, ..., -0.05536823,\n",
       "         -0.05355338,  0.08556524],\n",
       "        [-0.06914192,  0.04280024,  0.03550166, ...,  0.03356671,\n",
       "         -0.12326976,  0.07291862],\n",
       "        [-0.1137425 ,  0.06552146, -0.0147246 , ..., -0.01377592,\n",
       "         -0.12544954,  0.08971225],\n",
       "        ...,\n",
       "        [-0.1025148 ,  0.02952543, -0.01928156, ..., -0.03821175,\n",
       "         -0.04951939,  0.11133271],\n",
       "        [-0.09937093,  0.01798   ,  0.0371547 , ..., -0.01157762,\n",
       "         -0.04102365,  0.07009368],\n",
       "        [-0.02378323,  0.04184181,  0.02192802, ..., -0.01919457,\n",
       "         -0.04806473,  0.05496194]], dtype=float32),\n",
       " array([[-0.10093065, -0.04367781,  0.00304613, ...,  0.03540821,\n",
       "          0.12080996, -0.03319402],\n",
       "        [-0.00984639, -0.02156602,  0.02087951, ...,  0.04585709,\n",
       "          0.13622198,  0.0419487 ],\n",
       "        [-0.06010005,  0.06659613,  0.00206823, ...,  0.01632951,\n",
       "          0.06564369,  0.04122795],\n",
       "        ...,\n",
       "        [-0.00574971,  0.02111753,  0.03405036, ...,  0.01387505,\n",
       "          0.08241311,  0.03360737],\n",
       "        [-0.01262175, -0.09757403, -0.00358153, ...,  0.05531334,\n",
       "          0.10665727,  0.08454951],\n",
       "        [-0.07849789,  0.00105227,  0.01399027, ...,  0.06428029,\n",
       "          0.12444754,  0.01961169]], dtype=float32),\n",
       " array([[-0.07607998,  0.00702787,  0.05066743, ...,  0.03231946,\n",
       "         -0.04171785,  0.00975884],\n",
       "        [ 0.06096707, -0.02341203,  0.01103286, ...,  0.07281807,\n",
       "         -0.0247668 , -0.01609928],\n",
       "        [ 0.03670458, -0.0010227 ,  0.00745087, ...,  0.08051895,\n",
       "         -0.08113801,  0.03991193],\n",
       "        ...,\n",
       "        [ 0.03547718,  0.02404794, -0.00954523, ..., -0.03995993,\n",
       "          0.02883198,  0.01193508],\n",
       "        [ 0.04190931, -0.02284714,  0.03385408, ...,  0.00651757,\n",
       "         -0.0932228 , -0.0094926 ],\n",
       "        [ 0.03292648, -0.01726757,  0.04950639, ..., -0.00289772,\n",
       "         -0.07584173,  0.0849084 ]], dtype=float32),\n",
       " array([[-0.01376325,  0.06298774, -0.03107748, ..., -0.07181686,\n",
       "         -0.11459427,  0.05146513],\n",
       "        [-0.00168593,  0.05660898, -0.07491387, ..., -0.06437829,\n",
       "         -0.10869522,  0.02811687],\n",
       "        [-0.03939132,  0.03475463,  0.00334448, ..., -0.02147149,\n",
       "         -0.06545439,  0.05212989],\n",
       "        ...,\n",
       "        [ 0.02403889,  0.01308808, -0.0461575 , ..., -0.04733292,\n",
       "         -0.09350839,  0.05626409],\n",
       "        [-0.01912043,  0.03923815, -0.04513641, ..., -0.04859143,\n",
       "         -0.10518836,  0.05231472],\n",
       "        [-0.0002697 ,  0.08506484, -0.02648402, ..., -0.0776992 ,\n",
       "         -0.09579067,  0.04337598]], dtype=float32),\n",
       " array([[ 0.06828462, -0.00600157,  0.01372422, ...,  0.10114201,\n",
       "          0.01457911,  0.04894537],\n",
       "        [ 0.03699831,  0.0406065 ,  0.03665286, ...,  0.08066805,\n",
       "          0.01587142,  0.07209414],\n",
       "        [ 0.03223936, -0.00144142, -0.01053306, ...,  0.10322879,\n",
       "          0.05907062,  0.02318056],\n",
       "        ...,\n",
       "        [ 0.06270797, -0.0047619 , -0.02195406, ...,  0.14014794,\n",
       "          0.11273813,  0.03572053],\n",
       "        [ 0.07594441,  0.01233404,  0.0229632 , ...,  0.13630362,\n",
       "          0.00424323, -0.05000595],\n",
       "        [ 0.04377728,  0.06095687,  0.05713087, ...,  0.07583135,\n",
       "          0.01257289, -0.00572273]], dtype=float32),\n",
       " array([[ 0.02882501,  0.02720143, -0.06280498, ...,  0.01570522,\n",
       "          0.06280334, -0.00730905],\n",
       "        [-0.0099409 ,  0.00162254,  0.05166364, ..., -0.0623249 ,\n",
       "         -0.0013896 ,  0.06605177],\n",
       "        [ 0.13151094,  0.02853992, -0.01568165, ...,  0.07736865,\n",
       "          0.00925446, -0.00226782],\n",
       "        ...,\n",
       "        [-0.02283423,  0.07768033,  0.00221816, ...,  0.04020821,\n",
       "          0.00585539,  0.01550946],\n",
       "        [-0.01408675,  0.00717395,  0.04244339, ..., -0.08271024,\n",
       "          0.0524013 ,  0.11518734],\n",
       "        [ 0.08434878,  0.03777801,  0.03030104, ...,  0.05031536,\n",
       "          0.03255859, -0.00945625]], dtype=float32),\n",
       " array([[-0.08521064,  0.10271879, -0.03041875, ..., -0.08402435,\n",
       "          0.10827601,  0.0612128 ],\n",
       "        [-0.05914396, -0.06161208, -0.0644546 , ..., -0.03320428,\n",
       "          0.06389737,  0.04556015],\n",
       "        [-0.05930742, -0.09315337, -0.03815472, ...,  0.03056497,\n",
       "          0.0286986 ,  0.09701478],\n",
       "        ...,\n",
       "        [-0.03617903,  0.03031899,  0.06420023, ...,  0.01921269,\n",
       "          0.03920601, -0.03699748],\n",
       "        [-0.04701533,  0.0232876 , -0.01767596, ..., -0.00977681,\n",
       "          0.04762714,  0.03914793],\n",
       "        [-0.06471614,  0.11937056, -0.00597377, ..., -0.04218034,\n",
       "         -0.02796126,  0.00723356]], dtype=float32),\n",
       " array([[-0.04605254,  0.05900763, -0.02331837, ..., -0.02319588,\n",
       "         -0.07381924, -0.00646483],\n",
       "        [ 0.02764472,  0.00474767, -0.03243089, ..., -0.02018248,\n",
       "         -0.06624882,  0.01801426],\n",
       "        [-0.04920343,  0.05588562, -0.03376513, ...,  0.05266289,\n",
       "          0.03554013, -0.00973519],\n",
       "        ...,\n",
       "        [-0.07984469,  0.08979915, -0.05269193, ..., -0.01118971,\n",
       "         -0.04345213,  0.05239937],\n",
       "        [-0.01719867,  0.08240748,  0.02021136, ...,  0.0040125 ,\n",
       "         -0.07424626,  0.03661958],\n",
       "        [ 0.00836191,  0.02278412,  0.01587678, ...,  0.0669146 ,\n",
       "         -0.09063885,  0.01894677]], dtype=float32)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b45f185",
   "metadata": {},
   "source": [
    "## Interpretation of Convex Hull\n",
    "The larger the convex hull, the more volume the embedding space takes in 3D space. This is a diversity measurement, but it must be considered that this volume calculation does not consider how many clusters there are. Therefore, it captures the edge cases that GPT might calculate and then the diversity of the solution may be greater than human solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "83ba1a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import ConvexHull\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "28d9ff37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume of human convex hull: 0.24920921368630627 | generated convex hull: 0.32414290190684225 | Difference: 0.07493368822053598\n",
      "Volume of human convex hull: 0.24362950965191404 | generated convex hull: 0.1970649608202382 | Difference: -0.04656454883167585\n",
      "Volume of human convex hull: 0.3216490475307161 | generated convex hull: 0.2381245599552197 | Difference: -0.08352448757549641\n",
      "Volume of human convex hull: 0.3170534306855752 | generated convex hull: 0.19324097771937304 | Difference: -0.12381245296620214\n",
      "Volume of human convex hull: 0.3383896149055536 | generated convex hull: 0.36796906298895854 | Difference: 0.029579448083404958\n",
      "Volume of human convex hull: 0.2610362838906081 | generated convex hull: 0.1641975463277175 | Difference: -0.09683873756289063\n",
      "Volume of human convex hull: 0.3302783400363774 | generated convex hull: 0.307938172149308 | Difference: -0.022340167887069384\n",
      "Volume of human convex hull: 0.27659003986012826 | generated convex hull: 0.12095790133636541 | Difference: -0.15563213852376284\n",
      "Volume of human convex hull: 0.3270883277780447 | generated convex hull: 0.19648421655245954 | Difference: -0.13060411122558516\n",
      "Volume of human convex hull: 0.3065662541377364 | generated convex hull: 0.3997078182076905 | Difference: 0.09314156406995411\n",
      "Volume of human convex hull: 0.30279813260917304 | generated convex hull: 0.27968560074007887 | Difference: -0.023112531869094177\n",
      "Volume of human convex hull: 0.2540898844997239 | generated convex hull: 0.320867391429607 | Difference: 0.0667775069298831\n"
     ]
    }
   ],
   "source": [
    "human_convex_lst = []\n",
    "generated_convex_lst = []\n",
    "diff_lst =[]\n",
    "pca = PCA(n_components=3)\n",
    "writers = zip(human_embeddings, generated_embeddings)\n",
    "for writer in writers:\n",
    "    datapoints_human = pca.fit_transform(writer[0])\n",
    "    hull_human = ConvexHull(datapoints_human)\n",
    "    volume_human = hull_human.volume\n",
    "    human_convex_lst.append(volume_human)\n",
    "\n",
    "    datapoints_generated = pca.fit_transform(writer[1])\n",
    "    hull_generated = ConvexHull(datapoints_generated)\n",
    "    volume_generated = hull_generated.volume\n",
    "    generated_convex_lst.append(volume_generated)\n",
    "\n",
    "    diff_lst.append(volume_generated - volume_human)\n",
    "\n",
    "    print(f\"Volume of human convex hull: {volume_human} | generated convex hull: {volume_generated} | Difference: {volume_generated - volume_human}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aaf2a807",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoints_human = pca.fit_transform(human_embeddings[6])\n",
    "hull_human = ConvexHull(datapoints_human)\n",
    "volume_human = hull_human.volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c12affa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29403150660598804"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(human_convex_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3b750067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.033464609682179805"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(human_convex_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b8d6fd51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2591984258444882"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(generated_convex_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f03cd95e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08322350247700687"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(generated_convex_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1937dca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.03483308076149987"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(diff_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2b56fd7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08227413326821371"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(diff_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8afa93",
   "metadata": {},
   "source": [
    "## Average L2 distance of the embeddings from the centroid\n",
    "Just as a caveat, the centroid of an embedding space can actually be quite unique within the solution space. But the average distance of all embeddings to the centroid measures how unique the model was able to generate solutions from a specific point.\n",
    "\n",
    "The centroid can be calculated as following\n",
    "Given a set of points \n",
    "\n",
    "$$x = (x_{1}, x_{2}, x_{3}, ..., x_{n}), y = (y_{1}, y_{2}, y_{3}, ..., y_{n}), z = (z_{1}, z_{2}, z_{3}, ..., z_{n})$$\n",
    "\n",
    "Calculate the centroid $a$\n",
    "\n",
    "$$ a = (\\frac{x_{1}+..+x_{n}}{n}, \\frac{y_{1}+..+y_{n}}{n}, \\frac{z_{1}+..+z_{n}}{n}) $$\n",
    "\n",
    "Note, a robust way to find a \"good\" centerpoint would be to ignore the top and bottom 10% in these 3 dimensions and then calculate the centroid using the data above.\n",
    "\n",
    "Note, we are also calculating the L2 distance for all points in the 3 dimensional space to the calculated centroid. We do this by considering this equation.\n",
    "\n",
    "$$ D(p,q) = \\sqrt{(p_{1}-q_{1})^2+(p_{2}-q_{2})^2+(p_{3}-q_{3})^2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "121de08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average L2 distance between human embedding values and human centroid value: 0.32275286316871643\n",
      "Average L2 distance between generated embedding values and generated centroid value: 0.36562973260879517\n",
      "Average L2 distance between human embedding values and human centroid value: 0.3123707175254822\n",
      "Average L2 distance between generated embedding values and generated centroid value: 0.3100925385951996\n",
      "Average L2 distance between human embedding values and human centroid value: 0.33655765652656555\n",
      "Average L2 distance between generated embedding values and generated centroid value: 0.3913555443286896\n",
      "Average L2 distance between human embedding values and human centroid value: 0.3156791627407074\n",
      "Average L2 distance between generated embedding values and generated centroid value: 0.2982226312160492\n",
      "Average L2 distance between human embedding values and human centroid value: 0.34407535195350647\n",
      "Average L2 distance between generated embedding values and generated centroid value: 0.4232231080532074\n",
      "Average L2 distance between human embedding values and human centroid value: 0.31044602394104004\n",
      "Average L2 distance between generated embedding values and generated centroid value: 0.2468407303094864\n",
      "Average L2 distance between human embedding values and human centroid value: 0.35027503967285156\n",
      "Average L2 distance between generated embedding values and generated centroid value: 0.385399729013443\n",
      "Average L2 distance between human embedding values and human centroid value: 0.3430647552013397\n",
      "Average L2 distance between generated embedding values and generated centroid value: 0.2805134057998657\n",
      "Average L2 distance between human embedding values and human centroid value: 0.3434910178184509\n",
      "Average L2 distance between generated embedding values and generated centroid value: 0.3221365213394165\n",
      "Average L2 distance between human embedding values and human centroid value: 0.3610369563102722\n",
      "Average L2 distance between generated embedding values and generated centroid value: 0.4645444452762604\n",
      "Average L2 distance between human embedding values and human centroid value: 0.3520719110965729\n",
      "Average L2 distance between generated embedding values and generated centroid value: 0.43557724356651306\n",
      "Average L2 distance between human embedding values and human centroid value: 0.3583928942680359\n",
      "Average L2 distance between generated embedding values and generated centroid value: 0.4398218095302582\n"
     ]
    }
   ],
   "source": [
    "euc_dist_human_lst = []\n",
    "euc_dist_generated_lst = []\n",
    "pca = PCA(n_components=3)\n",
    "writers = zip(human_embeddings, generated_embeddings)\n",
    "for writer in writers:\n",
    "    # pca dimensional reduction\n",
    "    datapoints_human = pca.fit_transform(writer[0])\n",
    "    # get x_coords, y_coords, z_coords\n",
    "    x_coords_human = datapoints_human[:,0]\n",
    "    y_coords_human = datapoints_human[:,1]\n",
    "    z_coords_human = datapoints_human[:,2]\n",
    "    # calculate centroids\n",
    "    x_centroid_human = np.mean(x_coords_human)\n",
    "    y_centroid_human = np.mean(y_coords_human)\n",
    "    z_centroid_human = np.mean(z_coords_human)\n",
    "    # find L2 distance\n",
    "    centroid_human = np.array([x_centroid_human, y_centroid_human, z_centroid_human])\n",
    "    # output 100 distance values\n",
    "    euc_dist_human = np.linalg.norm(datapoints_human-centroid_human, axis = 1)\n",
    "    euc_dist_human_lst.append(euc_dist_human)\n",
    "    \n",
    "    # pca dimensional reduction\n",
    "    datapoints_generated = pca.fit_transform(writer[1])\n",
    "    # get x_coords, y_coords, z_coords\n",
    "    x_coords_generated = datapoints_generated[:,0]\n",
    "    y_coords_generated = datapoints_generated[:,1]\n",
    "    z_coords_generated = datapoints_generated[:,2]\n",
    "    # calculate centroids\n",
    "    x_centroid_generated = np.mean(x_coords_generated)\n",
    "    y_centroid_generated = np.mean(y_coords_generated)\n",
    "    z_centroid_generated = np.mean(z_coords_generated)\n",
    "    # find L2 distance\n",
    "    centroid_generated = np.array([x_centroid_generated, y_centroid_generated, z_centroid_generated])\n",
    "    # output 100 distance values\n",
    "    euc_dist_generated = np.linalg.norm(datapoints_generated-centroid_generated, axis = 1)    \n",
    "    euc_dist_generated_lst.append(euc_dist_generated)\n",
    "    print(f\"Average L2 distance between human embedding values and human centroid value: {np.mean(euc_dist_human)}\")\n",
    "    print(f\"Average L2 distance between generated embedding values and generated centroid value: {np.mean(euc_dist_generated)}\")  \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0faa05dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human mean  0.33751786\n",
      "human std  0.12667356\n"
     ]
    }
   ],
   "source": [
    "print('human mean ', np.mean(euc_dist_human_lst))\n",
    "print('human std ', np.std(euc_dist_human_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aad0deec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated mean  0.36361313\n",
      "generated std  0.13973679\n"
     ]
    }
   ],
   "source": [
    "print('generated mean ', np.mean(euc_dist_generated_lst))\n",
    "print('generated std ', np.std(euc_dist_generated_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b20c4dac",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rando_dist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39mmean(\u001b[43mrando_dist\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rando_dist' is not defined"
     ]
    }
   ],
   "source": [
    "np.mean(rando_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f52f50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(datapoints_human-rando_centroid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7ebc34",
   "metadata": {},
   "source": [
    "## Attempt at using K-Means to improve PCA\n",
    "The idea is that we can use K-Means to cluster our data and analyze whether the PCA results actually mean something. Not sure how useful it is since we already have clusters.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a29755",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# fit k means using the transformed data from the PCA\n",
    "wcss = []\n",
    "for i in range(1, 21):\n",
    "    kmeans_pca = KMeans(n_clusters = i, random_state = 42)\n",
    "    kmeans_pca.fit(datapoints_human)\n",
    "    wcss.append(kmeans_pca.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3edd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(1,21), wcss, marker = 'o', linestyle = '--')\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"WCSS\")\n",
    "plt.title(\"K-Means w/ PCA Clustering\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3792a670",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Chosen 5 clusters? So run K-means with number of clusters = 5\n",
    "# Same initializer and random state as before\n",
    "kmeans_pca = KMeans(n_clusters = 4, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a940434e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit data with the k-means PCA model\n",
    "kmeans_pca.fit(datapoints_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fa6a65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:chatgpt]",
   "language": "python",
   "name": "conda-env-chatgpt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
