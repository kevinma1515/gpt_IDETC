{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88316a13",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e25a774",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Design prompt 1, human prompts\n",
    "human1 = []\n",
    "with open(\"data/amazonTurkDesPrompt1.csv\", 'r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    for row in csvreader:\n",
    "        human1.append(row[0])\n",
    "human1 = [i.replace('\\n',' ') for i in human1]    # Removing the line breaks as they mess with tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5b877c3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "human2 = []\n",
    "with open(\"data/amazonTurkDesPrompt2.csv\", 'r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    for row in csvreader:\n",
    "        human2.append(row[0])\n",
    "human2 = [i.replace('\\n',' ') for i in human2]    # Removing the line breaks as they mess with tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e4f9c5c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "human3 = []\n",
    "with open(\"data/amazonTurkDesPrompt3.csv\", 'r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    for row in csvreader:\n",
    "        human3.append(row[0])\n",
    "human3 = [i.replace('\\n',' ') for i in human3]    # Removing the line breaks as they mess with tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65844746",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "human4 = []\n",
    "with open(\"data/amazonTurkDesPrompt4.csv\", 'r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    for row in csvreader:\n",
    "        human4.append(row[0])\n",
    "human4 = [i.replace('\\n',' ') for i in human4] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd07bed5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "human5 = []\n",
    "with open(\"data/amazonTurkDesPrompt5.csv\", 'r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    for row in csvreader:\n",
    "        human5.append(row[0])\n",
    "human5 = [i.replace('\\n',' ') for i in human5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "badb6df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "human6 = []\n",
    "with open(\"data/amazonTurkDesPrompt6.csv\", 'r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    for row in csvreader:\n",
    "        human6.append(row[0])\n",
    "human6 = [i.replace('\\n',' ') for i in human6] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d131868a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "human7 = []\n",
    "with open(\"data/amazonTurkDesPrompt7.csv\", 'r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    for row in csvreader:\n",
    "        human7.append(row[0])\n",
    "human7 = [i.replace('\\n',' ') for i in human7] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a4a59e6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "human8 = []\n",
    "with open(\"data/amazonTurkDesPrompt8.csv\", 'r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    for row in csvreader:\n",
    "        human8.append(row[0])\n",
    "human8 = [i.replace('\\n',' ') for i in human8] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "233d1612",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "human9 = []\n",
    "with open(\"data/amazonTurkDesPrompt9.csv\", 'r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    for row in csvreader:\n",
    "        human9.append(row[0])\n",
    "human9 = [i.replace('\\n',' ') for i in human9] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccc13e0d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "human10 = []\n",
    "with open(\"data/amazonTurkDesPrompt10.csv\", 'r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    for row in csvreader:\n",
    "        human10.append(row[0])\n",
    "human10 = [i.replace('\\n',' ') for i in human10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adaba7e6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "human11 = []\n",
    "with open(\"data/amazonTurkDesPrompt11.csv\", 'r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    for row in csvreader:\n",
    "        human11.append(row[0])\n",
    "human11 = [i.replace('\\n',' ') for i in human11] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab4dfcda",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "humanNA = []\n",
    "with open(\"data/amazonTurkDesPromptNA.csv\", 'r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    for row in csvreader:\n",
    "        humanNA.append(row[0])\n",
    "humanNA = [i.replace('\\n',' ') for i in humanNA] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77698907",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Design prompt 1, gpt prompts\n",
    "desprompt1 = pd.read_csv('data/Design_Prompt1.csv', sep = \",\", header=None)\n",
    "lst1 = []\n",
    "for d in desprompt1.values:\n",
    "    lst1.append(d[0])\n",
    "gpt1 = []\n",
    "for i in range(len(lst1)):\n",
    "    mod_statements1 = lst1[i].replace(lst1[i][:3], '')\n",
    "    gpt1.append(mod_statements1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b73ee13d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Design Prompt 2, gpt prompts\n",
    "desprompt2 = pd.read_csv('data/Design_Prompt2.csv', sep = \",\", header = None)\n",
    "lst2 = []\n",
    "for d in desprompt2.values:\n",
    "    lst2.append(d[0])\n",
    "gpt2 = []\n",
    "for i in range(len(lst2)):\n",
    "    mod_statements2 = lst2[i].replace(lst2[i][:3], '')\n",
    "    gpt2.append(mod_statements2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d903a168",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Design Prompt 3, gpt prompts\n",
    "desprompt3 = pd.read_csv('data/Design_Prompt3.csv', sep = \",\", header = None)\n",
    "lst3 = []\n",
    "for d in desprompt3.values:\n",
    "    lst3.append(d[0])\n",
    "gpt3 = []\n",
    "for i in range(len(lst3)):\n",
    "    mod_statements3 = lst3[i].replace(lst3[i][:3], '')\n",
    "    gpt3.append(mod_statements3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ebfe381",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "desprompt4 = pd.read_csv('data/Design_Prompt4.csv', sep = \",\", header = None)\n",
    "lst4 = []\n",
    "for d in desprompt4.values:\n",
    "    lst4.append(d[0])\n",
    "gpt4 = []\n",
    "for i in range(len(lst4)):\n",
    "    mod_statements4 = lst4[i].replace(lst4[i][:3], '')\n",
    "    gpt4.append(mod_statements4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29ff4f02",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "desprompt5 = pd.read_csv('data/Design_Prompt5.csv', sep = \",\", header = None)\n",
    "lst5 = []\n",
    "for d in desprompt5.values:\n",
    "    lst5.append(d[0])\n",
    "gpt5 = []\n",
    "for i in range(len(lst5)):\n",
    "    mod_statements5 = lst5[i].replace(lst5[i][:3], '')\n",
    "    gpt5.append(mod_statements5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53a14dea",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "desprompt6 = pd.read_csv('data/Design_Prompt6.csv', sep = \",\", header = None)\n",
    "lst6 = []\n",
    "for d in desprompt6.values:\n",
    "    lst6.append(d[0])\n",
    "gpt6 = []\n",
    "for i in range(len(lst6)):\n",
    "    mod_statements6 = lst6[i].replace(lst6[i][:3], '')\n",
    "    gpt6.append(mod_statements6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b96b3e6f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "desprompt7 = pd.read_csv('data/Design_Prompt7.csv', sep = \",\", header = None)\n",
    "lst7 = []\n",
    "for d in desprompt7.values:\n",
    "    lst7.append(d[0])\n",
    "gpt7 = []\n",
    "for i in range(len(lst7)):\n",
    "    mod_statements7 = lst7[i].replace(lst7[i][:3], '')\n",
    "    gpt7.append(mod_statements7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1412a0db",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "desprompt8 = pd.read_csv('data/Design_Prompt8.csv', sep = \",\", header = None)\n",
    "lst8 = []\n",
    "for d in desprompt8.values:\n",
    "    lst8.append(d[0])\n",
    "gpt8 = []\n",
    "for i in range(len(lst8)):\n",
    "    mod_statements8 = lst8[i].replace(lst8[i][:3], '')\n",
    "    gpt8.append(mod_statements8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b59d06c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "desprompt9 = pd.read_csv('data/Design_Prompt9.csv', sep = \",\", header = None)\n",
    "lst9 = []\n",
    "for d in desprompt9.values:\n",
    "    lst9.append(d[0])\n",
    "gpt9 = []\n",
    "for i in range(len(lst9)):\n",
    "    mod_statements9 = lst9[i].replace(lst9[i][:3], '')\n",
    "    gpt9.append(mod_statements9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27d3f3d0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "desprompt10 = pd.read_csv('data/Design_Prompt10.csv', sep = \",\", header = None)\n",
    "lst10 = []\n",
    "for d in desprompt10.values:\n",
    "    lst10.append(d[0])\n",
    "gpt10 = []\n",
    "for i in range(len(lst10)):\n",
    "    mod_statements10 = lst10[i].replace(lst10[i][:3], '')\n",
    "    gpt10.append(mod_statements10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be24fa42",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "desprompt11 = pd.read_csv('data/Design_Prompt11.csv', sep = \",\", header = None)\n",
    "lst11 = []\n",
    "for d in desprompt11.values:\n",
    "    lst11.append(d[0])\n",
    "gpt11 = []\n",
    "for i in range(len(lst11)):\n",
    "    mod_statements11 = lst11[i].replace(lst11[i][:3], '')\n",
    "    gpt11.append(mod_statements11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7fa0d1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "desprompt12 = pd.read_csv('data/Design_Prompt12.csv', sep = \",\", header = None)\n",
    "lst12 = []\n",
    "for d in desprompt12.values:\n",
    "    lst12.append(d[0])\n",
    "gpt12 = []\n",
    "for i in range(len(lst12)):\n",
    "    mod_statements12 = lst12[i].replace(lst12[i][:3], '')\n",
    "    gpt12.append(mod_statements12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be465adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "despromptNA = pd.read_csv('data/Design_PromptNA.csv', sep = \",\", header = None)\n",
    "lstNA = []\n",
    "for d in despromptNA.values:\n",
    "    lstNA.append(d[0])\n",
    "gptNA = []\n",
    "for i in range(len(lstNA)):\n",
    "    mod_statementsNA = lstNA[i].replace(lstNA[i][:3], '')\n",
    "    gptNA.append(mod_statementsNA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e19c2fcf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# embed data\n",
    "# this is brute forced. Just easier to debug sometimes...\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "gpt1_embeddings = model.encode(gpt1)\n",
    "human1_embeddings = model.encode(human1)\n",
    "\n",
    "gpt2_embeddings = model.encode(gpt2)\n",
    "human2_embeddings = model.encode(human2)\n",
    "\n",
    "gpt3_embeddings = model.encode(gpt3)\n",
    "human3_embeddings = model.encode(human3)\n",
    "\n",
    "gpt4_embeddings = model.encode(gpt4)\n",
    "human4_embeddings = model.encode(human4)\n",
    "\n",
    "gpt5_embeddings = model.encode(gpt5)\n",
    "human5_embeddings = model.encode(human5)\n",
    "\n",
    "gpt7_embeddings = model.encode(gpt7)\n",
    "human7_embeddings = model.encode(human7)\n",
    "\n",
    "gpt8_embeddings = model.encode(gpt8)\n",
    "human8_embeddings = model.encode(human8)\n",
    "\n",
    "gpt9_embeddings = model.encode(gpt9)\n",
    "human9_embeddings = model.encode(human9)\n",
    "\n",
    "gpt10_embeddings = model.encode(gpt10)\n",
    "human10_embeddings = model.encode(human10)\n",
    "\n",
    "gpt11_embeddings = model.encode(gpt11)\n",
    "human11_embeddings = model.encode(human11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d141e2ac",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bert_human1 = torch.from_numpy(human1_embeddings)\n",
    "bert_gpt1 = torch.from_numpy(gpt1_embeddings)\n",
    "\n",
    "bert_human2 = torch.from_numpy(human2_embeddings)\n",
    "bert_gpt2 = torch.from_numpy(gpt2_embeddings)\n",
    "\n",
    "bert_human3 = torch.from_numpy(human3_embeddings)\n",
    "bert_gpt3 = torch.from_numpy(gpt3_embeddings)\n",
    "\n",
    "bert_human4 = torch.from_numpy(human4_embeddings)\n",
    "bert_gpt4 = torch.from_numpy(gpt4_embeddings)\n",
    "\n",
    "bert_human5 = torch.from_numpy(human5_embeddings)\n",
    "bert_gpt5 = torch.from_numpy(gpt5_embeddings)\n",
    "\n",
    "bert_human7 = torch.from_numpy(human7_embeddings)\n",
    "bert_gpt7 = torch.from_numpy(gpt7_embeddings)\n",
    "\n",
    "bert_human8 = torch.from_numpy(human8_embeddings)\n",
    "bert_gpt8 = torch.from_numpy(gpt8_embeddings)\n",
    "\n",
    "bert_human9 = torch.from_numpy(human9_embeddings)\n",
    "bert_gpt9 = torch.from_numpy(gpt9_embeddings)\n",
    "\n",
    "bert_human10 = torch.from_numpy(human10_embeddings)\n",
    "bert_gpt10 = torch.from_numpy(gpt10_embeddings)\n",
    "\n",
    "bert_human11 = torch.from_numpy(human11_embeddings)\n",
    "bert_gpt11 = torch.from_numpy(gpt11_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "611d1872",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt6_embeddings = model.encode(gpt6)\n",
    "human6_embeddings = model.encode(human6)\n",
    "\n",
    "bert_human6 = torch.from_numpy(human6_embeddings)\n",
    "bert_gpt6 = torch.from_numpy(gpt6_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "856c55cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gptNA_embeddings = model.encode(gptNA)\n",
    "humanNA_embeddings = model.encode(humanNA)\n",
    "\n",
    "bert_humanNA = torch.from_numpy(humanNA_embeddings)\n",
    "bert_gptNA = torch.from_numpy(gptNA_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f8c67eb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "# visualize embeddings\n",
    "writer = SummaryWriter('embeddings_total')\n",
    "metadata = [('human1', line) for line in human1] + [('gpt1', line) for line in gpt1] +\\\n",
    "            [('human2', line) for line in human2] + [('gpt2', line) for line in gpt2]+\\\n",
    "[('human3', line) for line in human3] + [('gpt3', line) for line in gpt3]+\\\n",
    "[('human4', line) for line in human4] + [('gpt4', line) for line in gpt4]+\\\n",
    "[('human5', line) for line in human5] + [('gpt5', line) for line in gpt5]+\\\n",
    "[('human7', line) for line in human7] + [('gpt7', line) for line in gpt7]+\\\n",
    "[('human6', line) for line in human6] + [('gpt6', line) for line in gpt6]+\\\n",
    "[('human8', line) for line in human8] + [('gpt8', line) for line in gpt8]+\\\n",
    "[('human9', line) for line in human9] + [('gpt9', line) for line in gpt9]+\\\n",
    "[('human10', line) for line in human10] + [('gpt10', line) for line in gpt10]+\\\n",
    "[('human11', line) for line in human11] + [('gpt11', line) for line in gpt11]+\\\n",
    "[('humanNA', line) for line in humanNA] + [('gptNA', line) for line in gptNA]\n",
    "\n",
    "\n",
    "writer.add_embedding(torch.cat((bert_human1, bert_gpt1, bert_human2, bert_gpt2, bert_human3, bert_gpt3, bert_human4, \n",
    "                                bert_gpt4, bert_human5, bert_gpt5, bert_human6, bert_gpt6, bert_human7, bert_gpt7, bert_human8, \n",
    "                                bert_gpt8, bert_human9, bert_gpt9, bert_human10, \n",
    "                                bert_gpt10, bert_human11, bert_gpt11, bert_humanNA, bert_gptNA), 0), metadata=metadata, metadata_header=['writer', 'prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ad87a5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "# visualize embeddings\n",
    "writer = SummaryWriter('embeddings1')\n",
    "metadata = [('human1', line) for line in human1] + [('gpt1', line) for line in gpt1]\n",
    "writer.add_embedding(torch.cat((bert_human1, bert_gpt1)),metadata = metadata, metadata_header = ['writer', 'prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d2d4625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "# visualize embeddings\n",
    "writer = SummaryWriter('embeddings2')\n",
    "metadata = [('human2', line) for line in human2] + [('gpt2', line) for line in gpt2]\n",
    "writer.add_embedding(torch.cat((bert_human2, bert_gpt2)),metadata = metadata, metadata_header = ['writer', 'prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7df6afc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "# visualize embeddings\n",
    "writer = SummaryWriter('embeddings3')\n",
    "metadata = [('human3', line) for line in human3] + [('gpt3', line) for line in gpt3]\n",
    "writer.add_embedding(torch.cat((bert_human3, bert_gpt3)),metadata = metadata, metadata_header = ['writer', 'prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "965869a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "# visualize embeddings\n",
    "writer = SummaryWriter('embeddings4')\n",
    "metadata = [('human4', line) for line in human4] + [('gpt4', line) for line in gpt4]\n",
    "writer.add_embedding(torch.cat((bert_human4, bert_gpt4)),metadata = metadata, metadata_header = ['writer', 'prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "962b410a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "# visualize embeddings\n",
    "writer = SummaryWriter('embeddings5')\n",
    "metadata = [('human5', line) for line in human5] + [('gpt5', line) for line in gpt5]\n",
    "writer.add_embedding(torch.cat((bert_human5, bert_gpt5)),metadata = metadata, metadata_header = ['writer', 'prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "77abbde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "# visualize embeddings\n",
    "writer = SummaryWriter('embeddings6')\n",
    "metadata = [('human6', line) for line in human6] + [('gpt6', line) for line in gpt6]\n",
    "writer.add_embedding(torch.cat((bert_human6, bert_gpt6)),metadata = metadata, metadata_header = ['writer', 'prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f42691d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "# visualize embeddings\n",
    "writer = SummaryWriter('embeddings7')\n",
    "metadata = [('human7', line) for line in human7] + [('gpt7', line) for line in gpt7]\n",
    "writer.add_embedding(torch.cat((bert_human7, bert_gpt7)),metadata = metadata, metadata_header = ['writer', 'prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ca54b6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "# visualize embeddings\n",
    "writer = SummaryWriter('embeddings8')\n",
    "metadata = [('human8', line) for line in human8] + [('gpt8', line) for line in gpt8]\n",
    "writer.add_embedding(torch.cat((bert_human8, bert_gpt8)),metadata = metadata, metadata_header = ['writer', 'prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8f398e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "# visualize embeddings\n",
    "writer = SummaryWriter('embeddings9')\n",
    "metadata = [('human9', line) for line in human9] + [('gpt9', line) for line in gpt9]\n",
    "writer.add_embedding(torch.cat((bert_human9, bert_gpt9)),metadata = metadata, metadata_header = ['writer', 'prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2920abd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "# visualize embeddings\n",
    "writer = SummaryWriter('embeddings10')\n",
    "metadata = [('human10', line) for line in human10] + [('gpt10', line) for line in gpt10]\n",
    "writer.add_embedding(torch.cat((bert_human10, bert_gpt10)),metadata = metadata, metadata_header = ['writer', 'prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d81b9dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "# visualize embeddings\n",
    "writer = SummaryWriter('embeddings11')\n",
    "metadata = [('human11', line) for line in human11] + [('gpt11', line) for line in gpt11]\n",
    "writer.add_embedding(torch.cat((bert_human11, bert_gpt11)),metadata = metadata, metadata_header = ['writer', 'prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3a0e2695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "# visualize embeddings\n",
    "writer = SummaryWriter('embeddingsNA')\n",
    "metadata = [('humanNA', line) for line in humanNA] + [('gptNA', line) for line in gptNA]\n",
    "writer.add_embedding(torch.cat((bert_humanNA, bert_gptNA)),metadata = metadata, metadata_header = ['writer', 'prompt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55272d6a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Run in terminal: tensorboard --logdir=\"embeddings\\\" --host localhost http://localhost:6006/ to open Tensorboard Refresh page.\n",
    "Note when you run from anaconda, conda activate chatgpt -> cd chatgpt -> run the terminal command above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fadd9b6",
   "metadata": {},
   "source": [
    "## How to interpret the cosine distance?\n",
    "\n",
    "Let two vectors $ a, b, \\theta$ be obtained by the scalar product and the norm of the vectors:\n",
    "$$ \\cos(\\theta) = \\frac{a \\cdot b}{||a|| \\cdot ||b||} $$\n",
    "Since $\\cos(\\theta)$ value is in the range $[-1 , 1]$:\n",
    "* $-1$ value will indicate strongly opposite vectors (a and b are very different)\n",
    "* $0$ independent (orthogonal) vectors (no correlation between a and b)\n",
    "* $1$ similar (positive co-linear) vecctors. Intermediate values are used to assess the degree of similarity. (a and b are very similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "41f0b8ae",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from statistics import mean\n",
    "generated_embeddings = [gpt1_embeddings, gpt2_embeddings, gpt3_embeddings, gpt4_embeddings, gpt5_embeddings, gpt6_embeddings, gpt7_embeddings, gpt8_embeddings, gpt9_embeddings, gpt10_embeddings, gpt11_embeddings, gptNA_embeddings]\n",
    "human_embeddings = [human1_embeddings, human2_embeddings, human3_embeddings, human4_embeddings, human5_embeddings, human6_embeddings, human7_embeddings, human8_embeddings, human9_embeddings, human10_embeddings, human11_embeddings, humanNA_embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b2e3cb3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Distance between human and generated embeddings: 0.3184424936771393\n",
      "Cosine Distance between human and generated embeddings: 0.33622682094573975\n",
      "Cosine Distance between human and generated embeddings: 0.33667927980422974\n",
      "Cosine Distance between human and generated embeddings: 0.4694971442222595\n",
      "Cosine Distance between human and generated embeddings: 0.3255586326122284\n",
      "Cosine Distance between human and generated embeddings: 0.5023563504219055\n",
      "Cosine Distance between human and generated embeddings: 0.2531582713127136\n",
      "Cosine Distance between human and generated embeddings: 0.4217812418937683\n",
      "Cosine Distance between human and generated embeddings: 0.446638822555542\n",
      "Cosine Distance between human and generated embeddings: 0.3235302269458771\n",
      "Cosine Distance between human and generated embeddings: 0.27407336235046387\n",
      "Cosine Distance between human and generated embeddings: 0.2649642825126648\n"
     ]
    }
   ],
   "source": [
    "# enumerate through generated_embeddings to get (100x384) or (99x384) vectors\n",
    "# count is just collecting the iterations\n",
    "distances = []\n",
    "for count in range(len(generated_embeddings)):\n",
    "    # human embeddings is also of length 11 and collect each human embedding via indexing\n",
    "    # cosine distance\n",
    "    distance = np.dot(human_embeddings[count].flatten(), generated_embeddings[count].flatten())/(norm(human_embeddings[count])*norm(generated_embeddings[count]))\n",
    "\n",
    "    distances.append(distance)\n",
    "    # mean_distance = mean(distances)\n",
    "    print(f\"Cosine Distance between human and generated embeddings: {distance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7583cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bc79747d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average:  0.35607556\n",
      "standard deviation:  0.07988324\n"
     ]
    }
   ],
   "source": [
    "print('average: ', np.mean(distances))\n",
    "print('standard deviation: ', np.std(distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b4ffcd29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.07354169,  0.05152091, -0.04160079, ..., -0.08609055,\n",
       "         -0.06903829,  0.07689107],\n",
       "        [-0.03084917,  0.12248117, -0.05312356, ..., -0.02598694,\n",
       "          0.00896085,  0.01969136],\n",
       "        [-0.0083613 , -0.02996279,  0.03444409, ..., -0.04331712,\n",
       "         -0.02330872,  0.03555185],\n",
       "        ...,\n",
       "        [ 0.05295016,  0.01373888, -0.02087503, ..., -0.00483859,\n",
       "          0.01642857, -0.057293  ],\n",
       "        [ 0.03174666,  0.00547677, -0.07130402, ...,  0.01611543,\n",
       "         -0.00663609,  0.03332655],\n",
       "        [-0.07669905,  0.08392771, -0.01675376, ..., -0.05440386,\n",
       "         -0.04658066,  0.07163215]], dtype=float32),\n",
       " array([[-0.07307021,  0.06389402, -0.04105479, ..., -0.07164105,\n",
       "          0.00118816,  0.05867276],\n",
       "        [-0.0175827 ,  0.11671401,  0.04160567, ..., -0.05293673,\n",
       "         -0.03432265,  0.06130178],\n",
       "        [-0.14772844,  0.05603454, -0.03409488, ..., -0.0357421 ,\n",
       "         -0.0155123 , -0.02847553],\n",
       "        ...,\n",
       "        [-0.1089557 ,  0.11090319,  0.01564019, ..., -0.04427239,\n",
       "          0.01106437,  0.02552062],\n",
       "        [-0.07229508,  0.04538236, -0.06084692, ..., -0.05895914,\n",
       "          0.0362076 ,  0.01212287],\n",
       "        [-0.07387491,  0.10402425, -0.00990104, ..., -0.09076039,\n",
       "         -0.07272806,  0.07288053]], dtype=float32),\n",
       " array([[-1.5916348e-02,  6.6009030e-02, -2.3783518e-04, ...,\n",
       "          1.0914160e-05,  3.9997605e-05, -9.1188829e-03],\n",
       "        [-1.9380907e-03,  5.6339577e-02,  2.2381963e-02, ...,\n",
       "          4.7700352e-04,  6.0194857e-02,  3.3470849e-03],\n",
       "        [ 1.5144838e-02,  3.5295274e-02,  4.2999042e-03, ...,\n",
       "          3.0199094e-02,  8.7943217e-03,  3.3212965e-03],\n",
       "        ...,\n",
       "        [ 7.0361691e-03,  4.4476844e-02, -1.3686864e-03, ...,\n",
       "          9.2876136e-02,  3.4146950e-02, -7.5347410e-03],\n",
       "        [ 6.6905511e-03,  3.8164128e-02, -1.1930837e-02, ...,\n",
       "          6.3235447e-02, -3.6968723e-02, -4.0142320e-02],\n",
       "        [-3.0230720e-02,  1.1508557e-01, -1.2095241e-02, ...,\n",
       "          3.1198122e-02, -5.5594053e-02, -3.7862565e-02]], dtype=float32),\n",
       " array([[-5.9273902e-02, -1.8829209e-03,  3.1711128e-02, ...,\n",
       "          3.2462951e-02, -2.7068753e-02, -3.9977275e-02],\n",
       "        [ 6.5188673e-03,  4.6116065e-02,  7.0556790e-02, ...,\n",
       "          8.9820579e-02, -8.1339799e-02,  4.4463757e-02],\n",
       "        [ 1.2105356e-03,  4.3282327e-03,  1.5004859e-02, ...,\n",
       "          5.2089542e-02, -1.4204554e-03, -4.0399093e-02],\n",
       "        ...,\n",
       "        [-5.5817548e-02, -1.0888167e-02,  2.4057740e-02, ...,\n",
       "          4.0353827e-02, -1.4483667e-02, -2.0518877e-02],\n",
       "        [-5.6799360e-02, -8.3119273e-03,  3.2000348e-02, ...,\n",
       "          4.3590821e-02,  2.6709247e-02, -5.3935073e-02],\n",
       "        [ 1.1955325e-03, -6.3613420e-06,  6.0106455e-03, ...,\n",
       "          6.3283086e-02,  4.7650281e-02, -8.1872828e-03]], dtype=float32),\n",
       " array([[-0.09659813,  0.0205404 ,  0.02748104, ..., -0.05536823,\n",
       "         -0.05355338,  0.08556524],\n",
       "        [-0.06914192,  0.04280024,  0.03550166, ...,  0.03356671,\n",
       "         -0.12326976,  0.07291862],\n",
       "        [-0.1137425 ,  0.06552146, -0.0147246 , ..., -0.01377592,\n",
       "         -0.12544954,  0.08971225],\n",
       "        ...,\n",
       "        [-0.1025148 ,  0.02952543, -0.01928156, ..., -0.03821175,\n",
       "         -0.04951939,  0.11133271],\n",
       "        [-0.09937093,  0.01798   ,  0.0371547 , ..., -0.01157762,\n",
       "         -0.04102365,  0.07009368],\n",
       "        [-0.02378323,  0.04184181,  0.02192802, ..., -0.01919457,\n",
       "         -0.04806473,  0.05496194]], dtype=float32),\n",
       " array([[-0.10093065, -0.04367781,  0.00304613, ...,  0.03540821,\n",
       "          0.12080996, -0.03319402],\n",
       "        [-0.00984639, -0.02156602,  0.02087951, ...,  0.04585709,\n",
       "          0.13622198,  0.0419487 ],\n",
       "        [-0.06010005,  0.06659613,  0.00206823, ...,  0.01632951,\n",
       "          0.06564369,  0.04122795],\n",
       "        ...,\n",
       "        [-0.00574971,  0.02111753,  0.03405036, ...,  0.01387505,\n",
       "          0.08241311,  0.03360737],\n",
       "        [-0.01262175, -0.09757403, -0.00358153, ...,  0.05531334,\n",
       "          0.10665727,  0.08454951],\n",
       "        [-0.07849789,  0.00105227,  0.01399027, ...,  0.06428029,\n",
       "          0.12444754,  0.01961169]], dtype=float32),\n",
       " array([[-0.07607998,  0.00702787,  0.05066743, ...,  0.03231946,\n",
       "         -0.04171785,  0.00975884],\n",
       "        [ 0.06096707, -0.02341203,  0.01103286, ...,  0.07281807,\n",
       "         -0.0247668 , -0.01609928],\n",
       "        [ 0.03670458, -0.0010227 ,  0.00745087, ...,  0.08051895,\n",
       "         -0.08113801,  0.03991193],\n",
       "        ...,\n",
       "        [ 0.03547718,  0.02404794, -0.00954523, ..., -0.03995993,\n",
       "          0.02883198,  0.01193508],\n",
       "        [ 0.04190931, -0.02284714,  0.03385408, ...,  0.00651757,\n",
       "         -0.0932228 , -0.0094926 ],\n",
       "        [ 0.03292648, -0.01726757,  0.04950639, ..., -0.00289772,\n",
       "         -0.07584173,  0.0849084 ]], dtype=float32),\n",
       " array([[-0.01376325,  0.06298774, -0.03107748, ..., -0.07181686,\n",
       "         -0.11459427,  0.05146513],\n",
       "        [-0.00168593,  0.05660898, -0.07491387, ..., -0.06437829,\n",
       "         -0.10869522,  0.02811687],\n",
       "        [-0.03939132,  0.03475463,  0.00334448, ..., -0.02147149,\n",
       "         -0.06545439,  0.05212989],\n",
       "        ...,\n",
       "        [ 0.02403889,  0.01308808, -0.0461575 , ..., -0.04733292,\n",
       "         -0.09350839,  0.05626409],\n",
       "        [-0.01912043,  0.03923815, -0.04513641, ..., -0.04859143,\n",
       "         -0.10518836,  0.05231472],\n",
       "        [-0.0002697 ,  0.08506484, -0.02648402, ..., -0.0776992 ,\n",
       "         -0.09579067,  0.04337598]], dtype=float32),\n",
       " array([[ 0.06828462, -0.00600157,  0.01372422, ...,  0.10114201,\n",
       "          0.01457911,  0.04894537],\n",
       "        [ 0.03699831,  0.0406065 ,  0.03665286, ...,  0.08066805,\n",
       "          0.01587142,  0.07209414],\n",
       "        [ 0.03223936, -0.00144142, -0.01053306, ...,  0.10322879,\n",
       "          0.05907062,  0.02318056],\n",
       "        ...,\n",
       "        [ 0.06270797, -0.0047619 , -0.02195406, ...,  0.14014794,\n",
       "          0.11273813,  0.03572053],\n",
       "        [ 0.07594441,  0.01233404,  0.0229632 , ...,  0.13630362,\n",
       "          0.00424323, -0.05000595],\n",
       "        [ 0.04377728,  0.06095687,  0.05713087, ...,  0.07583135,\n",
       "          0.01257289, -0.00572273]], dtype=float32),\n",
       " array([[ 0.02882501,  0.02720143, -0.06280498, ...,  0.01570522,\n",
       "          0.06280334, -0.00730905],\n",
       "        [-0.0099409 ,  0.00162254,  0.05166364, ..., -0.0623249 ,\n",
       "         -0.0013896 ,  0.06605177],\n",
       "        [ 0.13151094,  0.02853992, -0.01568165, ...,  0.07736865,\n",
       "          0.00925446, -0.00226782],\n",
       "        ...,\n",
       "        [-0.02283423,  0.07768033,  0.00221816, ...,  0.04020821,\n",
       "          0.00585539,  0.01550946],\n",
       "        [-0.01408675,  0.00717395,  0.04244339, ..., -0.08271024,\n",
       "          0.0524013 ,  0.11518734],\n",
       "        [ 0.08434878,  0.03777801,  0.03030104, ...,  0.05031536,\n",
       "          0.03255859, -0.00945625]], dtype=float32),\n",
       " array([[-0.08521064,  0.10271879, -0.03041875, ..., -0.08402435,\n",
       "          0.10827601,  0.0612128 ],\n",
       "        [-0.05914396, -0.06161208, -0.0644546 , ..., -0.03320428,\n",
       "          0.06389737,  0.04556015],\n",
       "        [-0.05930742, -0.09315337, -0.03815472, ...,  0.03056497,\n",
       "          0.0286986 ,  0.09701478],\n",
       "        ...,\n",
       "        [-0.03617903,  0.03031899,  0.06420023, ...,  0.01921269,\n",
       "          0.03920601, -0.03699748],\n",
       "        [-0.04701533,  0.0232876 , -0.01767596, ..., -0.00977681,\n",
       "          0.04762714,  0.03914793],\n",
       "        [-0.06471614,  0.11937056, -0.00597377, ..., -0.04218034,\n",
       "         -0.02796126,  0.00723356]], dtype=float32),\n",
       " array([[-0.04605254,  0.05900763, -0.02331837, ..., -0.02319588,\n",
       "         -0.07381924, -0.00646483],\n",
       "        [ 0.02764472,  0.00474767, -0.03243089, ..., -0.02018248,\n",
       "         -0.06624882,  0.01801426],\n",
       "        [-0.04920343,  0.05588562, -0.03376513, ...,  0.05266289,\n",
       "          0.03554013, -0.00973519],\n",
       "        ...,\n",
       "        [-0.07984469,  0.08979915, -0.05269193, ..., -0.01118971,\n",
       "         -0.04345213,  0.05239937],\n",
       "        [-0.01719867,  0.08240748,  0.02021136, ...,  0.0040125 ,\n",
       "         -0.07424626,  0.03661958],\n",
       "        [ 0.00836191,  0.02278412,  0.01587678, ...,  0.0669146 ,\n",
       "         -0.09063885,  0.01894677]], dtype=float32)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9182e591",
   "metadata": {},
   "source": [
    "## Interpretation of Convex Hull\n",
    "The larger the convex hull, the more volume the embedding space takes in 3D space. This is a diversity measurement, but it must be considered that this volume calculation does not consider how many clusters there are. Therefore, it captures the edge cases that GPT might calculate and then the diversity of the solution may be greater than human solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "83ba1a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import ConvexHull\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "28d9ff37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume of human convex hull: 0.24920921368630627 | generated convex hull: 0.32414290190684225 | Difference: 0.07493368822053598\n",
      "Volume of human convex hull: 0.24362950965191404 | generated convex hull: 0.1970649608202382 | Difference: -0.04656454883167585\n",
      "Volume of human convex hull: 0.3216490475307161 | generated convex hull: 0.2381245599552197 | Difference: -0.08352448757549641\n",
      "Volume of human convex hull: 0.3170534306855752 | generated convex hull: 0.19324097771937304 | Difference: -0.12381245296620214\n",
      "Volume of human convex hull: 0.3383896149055536 | generated convex hull: 0.36796906298895854 | Difference: 0.029579448083404958\n",
      "Volume of human convex hull: 0.2610362838906081 | generated convex hull: 0.1641975463277175 | Difference: -0.09683873756289063\n",
      "Volume of human convex hull: 0.3302783400363774 | generated convex hull: 0.307938172149308 | Difference: -0.022340167887069384\n",
      "Volume of human convex hull: 0.27659003986012826 | generated convex hull: 0.12095790133636541 | Difference: -0.15563213852376284\n",
      "Volume of human convex hull: 0.3270883277780447 | generated convex hull: 0.19648421655245954 | Difference: -0.13060411122558516\n",
      "Volume of human convex hull: 0.3065662541377364 | generated convex hull: 0.3997078182076905 | Difference: 0.09314156406995411\n",
      "Volume of human convex hull: 0.30279813260917304 | generated convex hull: 0.27968560074007887 | Difference: -0.023112531869094177\n",
      "Volume of human convex hull: 0.2540898844997239 | generated convex hull: 0.320867391429607 | Difference: 0.0667775069298831\n"
     ]
    }
   ],
   "source": [
    "human_convex_lst = []\n",
    "generated_convex_lst = []\n",
    "diff_lst =[]\n",
    "pca = PCA(n_components=3)\n",
    "writers = zip(human_embeddings, generated_embeddings)\n",
    "for writer in writers:\n",
    "    datapoints_human = pca.fit_transform(writer[0])\n",
    "    hull_human = ConvexHull(datapoints_human)\n",
    "    volume_human = hull_human.volume\n",
    "    human_convex_lst.append(volume_human)\n",
    "\n",
    "    datapoints_generated = pca.fit_transform(writer[1])\n",
    "    hull_generated = ConvexHull(datapoints_generated)\n",
    "    volume_generated = hull_generated.volume\n",
    "    generated_convex_lst.append(volume_generated)\n",
    "\n",
    "    diff_lst.append(volume_generated - volume_human)\n",
    "\n",
    "    print(f\"Volume of human convex hull: {volume_human} | generated convex hull: {volume_generated} | Difference: {volume_generated - volume_human}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "46fe62ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoints_human = pca.fit_transform(human_embeddings[6])\n",
    "hull_human = ConvexHull(datapoints_human)\n",
    "volume_human = hull_human.volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0993cf1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29403150660598804"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(human_convex_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4d088144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.033464609682179805"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(human_convex_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1831fab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2591984258444882"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(generated_convex_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9c196a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08322350247700687"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(generated_convex_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f67a6dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.03483308076149987"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(diff_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fdd4f042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08227413326821371"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(diff_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686fdfd2",
   "metadata": {},
   "source": [
    "## Average L2 distance of the embeddings from the centroid\n",
    "Just as a caveat, the centroid of an embedding space can actually be quite unique within the solution space. But the average distance of all embeddings to the centroid measures how unique the model was able to generate solutions from a specific point.\n",
    "\n",
    "The centroid can be calculated as following\n",
    "Given a set of points \n",
    "\n",
    "$$x = (x_{1}, x_{2}, x_{3}, ..., x_{n}), y = (y_{1}, y_{2}, y_{3}, ..., y_{n}), z = (z_{1}, z_{2}, z_{3}, ..., z_{n})$$\n",
    "\n",
    "Calculate the centroid $a$\n",
    "\n",
    "$$ a = (\\frac{x_{1}+..+x_{n}}{n}, \\frac{y_{1}+..+y_{n}}{n}, \\frac{z_{1}+..+z_{n}}{n}) $$\n",
    "\n",
    "Note, a robust way to find a \"good\" centerpoint would be to ignore the top and bottom 10% in these 3 dimensions and then calculate the centroid using the data above.\n",
    "\n",
    "Note, we are also calculating the L2 distance for all points in the 3 dimensional space to the calculated centroid. We do this by considering this equation.\n",
    "\n",
    "$$ D(p,q) = \\sqrt{(p_{1}-q_{1})^2+(p_{2}-q_{2})^2+(p_{3}-q_{3})^2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6127df26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average L2 distance between human embedding values and human centroid value: 0.32275286316871643\n",
      "Average L2 distance between generated embedding values and generated centroid value: 0.36562973260879517\n",
      "Average L2 distance between human embedding values and human centroid value: 0.3123707175254822\n",
      "Average L2 distance between generated embedding values and generated centroid value: 0.3100925385951996\n",
      "Average L2 distance between human embedding values and human centroid value: 0.33655765652656555\n",
      "Average L2 distance between generated embedding values and generated centroid value: 0.3913555443286896\n",
      "Average L2 distance between human embedding values and human centroid value: 0.3156791627407074\n",
      "Average L2 distance between generated embedding values and generated centroid value: 0.2982226312160492\n",
      "Average L2 distance between human embedding values and human centroid value: 0.34407535195350647\n",
      "Average L2 distance between generated embedding values and generated centroid value: 0.4232231080532074\n",
      "Average L2 distance between human embedding values and human centroid value: 0.31044602394104004\n",
      "Average L2 distance between generated embedding values and generated centroid value: 0.2468407303094864\n",
      "Average L2 distance between human embedding values and human centroid value: 0.35027503967285156\n",
      "Average L2 distance between generated embedding values and generated centroid value: 0.385399729013443\n",
      "Average L2 distance between human embedding values and human centroid value: 0.3430647552013397\n",
      "Average L2 distance between generated embedding values and generated centroid value: 0.2805134057998657\n",
      "Average L2 distance between human embedding values and human centroid value: 0.3434910178184509\n",
      "Average L2 distance between generated embedding values and generated centroid value: 0.3221365213394165\n",
      "Average L2 distance between human embedding values and human centroid value: 0.3610369563102722\n",
      "Average L2 distance between generated embedding values and generated centroid value: 0.4645444452762604\n",
      "Average L2 distance between human embedding values and human centroid value: 0.3520719110965729\n",
      "Average L2 distance between generated embedding values and generated centroid value: 0.43557724356651306\n",
      "Average L2 distance between human embedding values and human centroid value: 0.3583928942680359\n",
      "Average L2 distance between generated embedding values and generated centroid value: 0.4398218095302582\n"
     ]
    }
   ],
   "source": [
    "euc_dist_human_lst = []\n",
    "euc_dist_generated_lst = []\n",
    "pca = PCA(n_components=3)\n",
    "writers = zip(human_embeddings, generated_embeddings)\n",
    "for writer in writers:\n",
    "    # pca dimensional reduction\n",
    "    datapoints_human = pca.fit_transform(writer[0])\n",
    "    # get x_coords, y_coords, z_coords\n",
    "    x_coords_human = datapoints_human[:,0]\n",
    "    y_coords_human = datapoints_human[:,1]\n",
    "    z_coords_human = datapoints_human[:,2]\n",
    "    # calculate centroids\n",
    "    x_centroid_human = np.mean(x_coords_human)\n",
    "    y_centroid_human = np.mean(y_coords_human)\n",
    "    z_centroid_human = np.mean(z_coords_human)\n",
    "    # find L2 distance\n",
    "    centroid_human = np.array([x_centroid_human, y_centroid_human, z_centroid_human])\n",
    "    # output 100 distance values\n",
    "    euc_dist_human = np.linalg.norm(datapoints_human-centroid_human, axis = 1)\n",
    "    euc_dist_human_lst.append(euc_dist_human)\n",
    "    \n",
    "    # pca dimensional reduction\n",
    "    datapoints_generated = pca.fit_transform(writer[1])\n",
    "    # get x_coords, y_coords, z_coords\n",
    "    x_coords_generated = datapoints_generated[:,0]\n",
    "    y_coords_generated = datapoints_generated[:,1]\n",
    "    z_coords_generated = datapoints_generated[:,2]\n",
    "    # calculate centroids\n",
    "    x_centroid_generated = np.mean(x_coords_generated)\n",
    "    y_centroid_generated = np.mean(y_coords_generated)\n",
    "    z_centroid_generated = np.mean(z_coords_generated)\n",
    "    # find L2 distance\n",
    "    centroid_generated = np.array([x_centroid_generated, y_centroid_generated, z_centroid_generated])\n",
    "    # output 100 distance values\n",
    "    euc_dist_generated = np.linalg.norm(datapoints_generated-centroid_generated, axis = 1)    \n",
    "    euc_dist_generated_lst.append(euc_dist_generated)\n",
    "    print(f\"Average L2 distance between human embedding values and human centroid value: {np.mean(euc_dist_human)}\")\n",
    "    print(f\"Average L2 distance between generated embedding values and generated centroid value: {np.mean(euc_dist_generated)}\")  \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ea00025f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human mean  0.33751786\n",
      "human std  0.12667356\n"
     ]
    }
   ],
   "source": [
    "print('human mean ', np.mean(euc_dist_human_lst))\n",
    "print('human std ', np.std(euc_dist_human_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "479c4afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated mean  0.36361313\n",
      "generated std  0.13973679\n"
     ]
    }
   ],
   "source": [
    "print('generated mean ', np.mean(euc_dist_generated_lst))\n",
    "print('generated std ', np.std(euc_dist_generated_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d2f2aea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9260149199705014"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rando_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "36501891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.451087983612364"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(datapoints_human-rando_centroid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7ebc34",
   "metadata": {},
   "source": [
    "## Attempt at using K-Means to improve PCA\n",
    "The idea is that we can use K-Means to cluster our data and analyze whether the PCA results actually mean something. Not sure how useful it is since we already have clusters.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "98a29755",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# fit k means using the transformed data from the PCA\n",
    "wcss = []\n",
    "for i in range(1, 21):\n",
    "    kmeans_pca = KMeans(n_clusters = i, random_state = 42)\n",
    "    kmeans_pca.fit(datapoints_human)\n",
    "    wcss.append(kmeans_pca.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "be3edd28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(1,21), wcss, marker = 'o', linestyle = '--')\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"WCSS\")\n",
    "plt.title(\"K-Means w/ PCA Clustering\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3792a670",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Chosen 5 clusters? So run K-means with number of clusters = 5\n",
    "# Same initializer and random state as before\n",
    "kmeans_pca = KMeans(n_clusters = 4, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a940434e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=4, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_clusters=4, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(n_clusters=4, random_state=42)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit data with the k-means PCA model\n",
    "kmeans_pca.fit(datapoints_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fa6a65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:chatgpt]",
   "language": "python",
   "name": "conda-env-chatgpt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
