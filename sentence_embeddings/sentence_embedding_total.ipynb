{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88316a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\anaconda3\\envs\\chatgpt\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e25a774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design prompt 1, human prompts\n",
    "human1 = []\n",
    "with open(\"amazonTurkDesPrompt1.csv\", 'r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    for row in csvreader:\n",
    "        human1.append(row[0])\n",
    "human1 = [i.replace('\\n',' ') for i in human1]    # Removing the line breaks as they mess with tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5b877c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "human2 = []\n",
    "with open(\"amazonTurkDesPrompt2.csv\", 'r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    for row in csvreader:\n",
    "        human2.append(row[0])\n",
    "human2 = [i.replace('\\n',' ') for i in human2]    # Removing the line breaks as they mess with tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e4f9c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "human3 = []\n",
    "with open(\"amazonTurkDesPrompt3.csv\", 'r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    for row in csvreader:\n",
    "        human3.append(row[0])\n",
    "human3 = [i.replace('\\n',' ') for i in human3]    # Removing the line breaks as they mess with tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65844746",
   "metadata": {},
   "outputs": [],
   "source": [
    "human4 = []\n",
    "with open(\"amazonTurkDesPrompt4.csv\", 'r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    for row in csvreader:\n",
    "        human4.append(row[0])\n",
    "human4 = [i.replace('\\n',' ') for i in human4] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd07bed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "human5 = []\n",
    "with open(\"amazonTurkDesPrompt5.csv\", 'r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    for row in csvreader:\n",
    "        human5.append(row[0])\n",
    "human5 = [i.replace('\\n',' ') for i in human5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d131868a",
   "metadata": {},
   "outputs": [],
   "source": [
    "human7 = []\n",
    "with open(\"amazonTurkDesPrompt7.csv\", 'r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    for row in csvreader:\n",
    "        human7.append(row[0])\n",
    "human7 = [i.replace('\\n',' ') for i in human7] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a4a59e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "human8 = []\n",
    "with open(\"amazonTurkDesPrompt8.csv\", 'r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    for row in csvreader:\n",
    "        human8.append(row[0])\n",
    "human8 = [i.replace('\\n',' ') for i in human8] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "233d1612",
   "metadata": {},
   "outputs": [],
   "source": [
    "human9 = []\n",
    "with open(\"amazonTurkDesPrompt9.csv\", 'r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    for row in csvreader:\n",
    "        human9.append(row[0])\n",
    "human9 = [i.replace('\\n',' ') for i in human9] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccc13e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "human10 = []\n",
    "with open(\"amazonTurkDesPrompt10.csv\", 'r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    for row in csvreader:\n",
    "        human10.append(row[0])\n",
    "human10 = [i.replace('\\n',' ') for i in human10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adaba7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "human11 = []\n",
    "with open(\"amazonTurkDesPrompt11.csv\", 'r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    for row in csvreader:\n",
    "        human11.append(row[0])\n",
    "human11 = [i.replace('\\n',' ') for i in human11] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab4dfcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "human12 = []\n",
    "with open(\"amazonTurkDesPrompt12.csv\", 'r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    for row in csvreader:\n",
    "        human12.append(row[0])\n",
    "human12 = [i.replace('\\n',' ') for i in human12] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77698907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design prompt 1, gpt prompts\n",
    "desprompt1 = pd.read_csv('Design_Prompt1.csv', sep = \",\")\n",
    "lst1 = []\n",
    "for d in desprompt1.values:\n",
    "    lst1.append(d[0])\n",
    "gpt1 = []\n",
    "for i in range(len(lst1)):\n",
    "    mod_statements1 = lst1[i].replace(lst1[i][:3], '')\n",
    "    gpt1.append(mod_statements1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b73ee13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design Prompt 2, gpt prompts\n",
    "desprompt2 = pd.read_csv('Design_Prompt2.csv', sep = \",\")\n",
    "lst2 = []\n",
    "for d in desprompt2.values:\n",
    "    lst2.append(d[0])\n",
    "gpt2 = []\n",
    "for i in range(len(lst2)):\n",
    "    mod_statements2 = lst2[i].replace(lst2[i][:3], '')\n",
    "    gpt2.append(mod_statements2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d903a168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design Prompt 3, gpt prompts\n",
    "desprompt3 = pd.read_csv('Design_Prompt3.csv', sep = \",\")\n",
    "lst3 = []\n",
    "for d in desprompt3.values:\n",
    "    lst3.append(d[0])\n",
    "gpt3 = []\n",
    "for i in range(len(lst3)):\n",
    "    mod_statements3 = lst3[i].replace(lst3[i][:3], '')\n",
    "    gpt3.append(mod_statements3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ebfe381",
   "metadata": {},
   "outputs": [],
   "source": [
    "desprompt4 = pd.read_csv('Design_Prompt4.csv', sep = \",\")\n",
    "lst4 = []\n",
    "for d in desprompt4.values:\n",
    "    lst4.append(d[0])\n",
    "gpt4 = []\n",
    "for i in range(len(lst4)):\n",
    "    mod_statements4 = lst4[i].replace(lst4[i][:3], '')\n",
    "    gpt4.append(mod_statements4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29ff4f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "desprompt5 = pd.read_csv('Design_Prompt5.csv', sep = \",\")\n",
    "lst5 = []\n",
    "for d in desprompt5.values:\n",
    "    lst5.append(d[0])\n",
    "gpt5 = []\n",
    "for i in range(len(lst5)):\n",
    "    mod_statements5 = lst5[i].replace(lst5[i][:3], '')\n",
    "    gpt5.append(mod_statements5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53a14dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "desprompt6 = pd.read_csv('Design_Prompt6.csv', sep = \",\")\n",
    "lst6 = []\n",
    "for d in desprompt6.values:\n",
    "    lst6.append(d[0])\n",
    "gpt6 = []\n",
    "for i in range(len(lst6)):\n",
    "    mod_statements6 = lst6[i].replace(lst6[i][:3], '')\n",
    "    gpt6.append(mod_statements6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b96b3e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "desprompt7 = pd.read_csv('Design_Prompt7.csv', sep = \",\")\n",
    "lst7 = []\n",
    "for d in desprompt7.values:\n",
    "    lst7.append(d[0])\n",
    "gpt7 = []\n",
    "for i in range(len(lst7)):\n",
    "    mod_statements7 = lst7[i].replace(lst7[i][:3], '')\n",
    "    gpt7.append(mod_statements7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1412a0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "desprompt8 = pd.read_csv('Design_Prompt8.csv', sep = \",\")\n",
    "lst8 = []\n",
    "for d in desprompt8.values:\n",
    "    lst8.append(d[0])\n",
    "gpt8 = []\n",
    "for i in range(len(lst8)):\n",
    "    mod_statements8 = lst8[i].replace(lst8[i][:3], '')\n",
    "    gpt8.append(mod_statements8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b59d06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "desprompt9 = pd.read_csv('Design_Prompt9.csv', sep = \",\")\n",
    "lst9 = []\n",
    "for d in desprompt9.values:\n",
    "    lst9.append(d[0])\n",
    "gpt9 = []\n",
    "for i in range(len(lst9)):\n",
    "    mod_statements9 = lst9[i].replace(lst9[i][:3], '')\n",
    "    gpt9.append(mod_statements9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27d3f3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "desprompt10 = pd.read_csv('Design_Prompt10.csv', sep = \",\")\n",
    "lst10 = []\n",
    "for d in desprompt10.values:\n",
    "    lst10.append(d[0])\n",
    "gpt10 = []\n",
    "for i in range(len(lst10)):\n",
    "    mod_statements10 = lst10[i].replace(lst10[i][:3], '')\n",
    "    gpt10.append(mod_statements10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be24fa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "desprompt11 = pd.read_csv('Design_Prompt11.csv', sep = \",\")\n",
    "lst11 = []\n",
    "for d in desprompt11.values:\n",
    "    lst11.append(d[0])\n",
    "gpt11 = []\n",
    "for i in range(len(lst11)):\n",
    "    mod_statements11 = lst11[i].replace(lst11[i][:3], '')\n",
    "    gpt11.append(mod_statements11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e19c2fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed data\n",
    "# this is brute forced. Just easier to debug sometimes...\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "gpt1_embeddings = model.encode(gpt1)\n",
    "human1_embeddings = model.encode(human1)\n",
    "\n",
    "gpt2_embeddings = model.encode(gpt2)\n",
    "human2_embeddings = model.encode(human2)\n",
    "\n",
    "gpt3_embeddings = model.encode(gpt3)\n",
    "human3_embeddings = model.encode(human3)\n",
    "\n",
    "gpt4_embeddings = model.encode(gpt4)\n",
    "human4_embeddings = model.encode(human4)\n",
    "\n",
    "gpt5_embeddings = model.encode(gpt5)\n",
    "human5_embeddings = model.encode(human5)\n",
    "\n",
    "gpt7_embeddings = model.encode(gpt7)\n",
    "human7_embeddings = model.encode(human7)\n",
    "\n",
    "gpt8_embeddings = model.encode(gpt8)\n",
    "human8_embeddings = model.encode(human8)\n",
    "\n",
    "gpt9_embeddings = model.encode(gpt9)\n",
    "human9_embeddings = model.encode(human9)\n",
    "\n",
    "gpt10_embeddings = model.encode(gpt10)\n",
    "human10_embeddings = model.encode(human10)\n",
    "\n",
    "gpt11_embeddings = model.encode(gpt11)\n",
    "human11_embeddings = model.encode(human11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d141e2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_human1 = torch.from_numpy(human1_embeddings)\n",
    "bert_gpt1 = torch.from_numpy(gpt1_embeddings)\n",
    "\n",
    "bert_human2 = torch.from_numpy(human2_embeddings)\n",
    "bert_gpt2 = torch.from_numpy(gpt2_embeddings)\n",
    "\n",
    "bert_human3 = torch.from_numpy(human3_embeddings)\n",
    "bert_gpt3 = torch.from_numpy(gpt3_embeddings)\n",
    "\n",
    "bert_human4 = torch.from_numpy(human4_embeddings)\n",
    "bert_gpt4 = torch.from_numpy(gpt4_embeddings)\n",
    "\n",
    "bert_human5 = torch.from_numpy(human5_embeddings)\n",
    "bert_gpt5 = torch.from_numpy(gpt5_embeddings)\n",
    "\n",
    "bert_human7 = torch.from_numpy(human7_embeddings)\n",
    "bert_gpt7 = torch.from_numpy(gpt7_embeddings)\n",
    "\n",
    "bert_human8 = torch.from_numpy(human8_embeddings)\n",
    "bert_gpt8 = torch.from_numpy(gpt8_embeddings)\n",
    "\n",
    "bert_human9 = torch.from_numpy(human9_embeddings)\n",
    "bert_gpt9 = torch.from_numpy(gpt9_embeddings)\n",
    "\n",
    "bert_human10 = torch.from_numpy(human10_embeddings)\n",
    "bert_gpt10 = torch.from_numpy(gpt10_embeddings)\n",
    "\n",
    "bert_human11 = torch.from_numpy(human11_embeddings)\n",
    "bert_gpt11 = torch.from_numpy(gpt11_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f8c67eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize embeddings\n",
    "writer = SummaryWriter('embeddings_total')\n",
    "metadata = [('human1', line) for line in human1] + [('gpt1', line) for line in gpt1] +\\\n",
    "            [('human2', line) for line in human2] + [('gpt2', line) for line in gpt2]+\\\n",
    "[('human3', line) for line in human3] + [('gpt3', line) for line in gpt3]+\\\n",
    "[('human4', line) for line in human4] + [('gpt4', line) for line in gpt4]+\\\n",
    "[('human5', line) for line in human5] + [('gpt5', line) for line in gpt5]+\\\n",
    "[('human7', line) for line in human7] + [('gpt7', line) for line in gpt7]+\\\n",
    "[('human8', line) for line in human8] + [('gpt8', line) for line in gpt8]+\\\n",
    "[('human9', line) for line in human9] + [('gpt9', line) for line in gpt9]+\\\n",
    "[('human10', line) for line in human10] + [('gpt10', line) for line in gpt10]+\\\n",
    "[('human11', line) for line in human11] + [('gpt11', line) for line in gpt11]\n",
    "\n",
    "\n",
    "writer.add_embedding(torch.cat((bert_human1, bert_gpt1, bert_human2, bert_gpt2, bert_human3, bert_gpt3, bert_human4, \n",
    "                                bert_gpt4, bert_human5, bert_gpt5, bert_human7, bert_gpt7, bert_human8, \n",
    "                                bert_gpt8, bert_human9, bert_gpt9, bert_human10, \n",
    "                                bert_gpt10, bert_human11, bert_gpt11), 0), metadata=metadata, metadata_header=['writer', 'prompt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55272d6a",
   "metadata": {},
   "source": [
    "Run in terminal: tensorboard --logdir=\"embeddings\\\" --host localhost http://localhost:6006/ to open Tensorboard Refresh page.\n",
    "Note when you run from anaconda, conda activate chatgpt -> cd chatgpt -> run the terminal command above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f0b8ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatgpt",
   "language": "python",
   "name": "chatgpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
